{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpretabilidad del modelo 9M"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports y funciones del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "false\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "valor = os.getenv(\"XLA_PYTHON_CLIENT_PREALLOCATE\")\n",
        "print(valor)\n",
        "\n",
        "if \"XLA_PYTHON_CLIENT_MEM_FRACTION\" in os.environ:\n",
        "    del os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BcWXEQI7Ws2l"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "\n",
        "import chess\n",
        "import chess.svg\n",
        "from IPython.display import SVG, display\n",
        "\n",
        "from jax import random as jrandom\n",
        "import jax\n",
        "import jax.nn as jnn\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import colors\n",
        "from matplotlib import gridspec\n",
        "import pickle\n",
        "import json\n",
        "import gc\n",
        "import random\n",
        "\n",
        "import networkx as nx\n",
        "import shap\n",
        "import lime\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "#os.chdir(\"/mnt/homeGPU/jorgelerre/S-ChessFormer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oUuSZBYyWvbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to import GCSFileSystem; loading of this filesystem will be skipped. Error details: cannot import name 'storage' from 'google.cloud' (unknown location)\n"
          ]
        }
      ],
      "source": [
        "from searchless_chess.src import transformer_xai\n",
        "importlib.reload(transformer_xai)\n",
        "from searchless_chess.src import tokenizer\n",
        "from searchless_chess.src import training_utils\n",
        "from searchless_chess.src import utils\n",
        "from searchless_chess.src.engines import engine\n",
        "from searchless_chess.src.engines import neural_engines\n",
        "import searchless_chess.src.engines.constants as constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8w6FnstXMr4"
      },
      "outputs": [],
      "source": [
        "# @title Create the predictor (9M)\n",
        "policy = 'action_value'\n",
        "num_return_buckets = 128\n",
        "num_heads = 8\n",
        "num_layers = 8\n",
        "embedding_dim = 256\n",
        "\n",
        "output_size = num_return_buckets\n",
        "predictor_config = transformer_xai.TransformerConfig(\n",
        "    vocab_size=utils.NUM_ACTIONS,\n",
        "    output_size=output_size,\n",
        "    pos_encodings=transformer_xai.PositionalEncodings.LEARNED,\n",
        "    max_sequence_length=tokenizer.SEQUENCE_LENGTH + 2,\n",
        "    num_heads=num_heads,\n",
        "    num_layers=num_layers,\n",
        "    embedding_dim=embedding_dim,\n",
        "    apply_post_ln=True,\n",
        "    apply_qk_layernorm=False,\n",
        "    use_causal_mask=False,\n",
        ")\n",
        "\n",
        "predictor = transformer_xai.build_transformer_predictor(config=predictor_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BZugSBZLXJxn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:[process=0][thread=MainThread] No metadata found for any process_index, checkpoint_dir=/mnt/homeGPU/jorgelerre/S-ChessFormer/searchless_chess/checkpoints/9M/6400000/params_ema. time elapsed=0.0012612342834472656 seconds. If the checkpoint does not contain jax.Array then it is expected. If checkpoint contains jax.Array then it should lead to an error eventually; if no error is raised then it is a bug.\n"
          ]
        }
      ],
      "source": [
        "# @title Load the predictor parameters\n",
        "os.chdir(\"/mnt/homeGPU/jorgelerre/S-ChessFormer\")\n",
        "checkpoint_dir = os.path.join(\n",
        "    os.getcwd(),\n",
        "    f'searchless_chess/checkpoints/9M',\n",
        ")\n",
        "dummy_params = predictor.initial_params(\n",
        "    rng=jrandom.PRNGKey(6400000),\n",
        "    targets=np.zeros((1, 1), dtype=np.uint32),\n",
        ")\n",
        "params = training_utils.load_parameters(\n",
        "    checkpoint_dir=checkpoint_dir,\n",
        "    params=dummy_params,\n",
        "    use_ema_params=True,\n",
        "    step=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Create the engine\n",
        "batch_size = 1\n",
        "jitted_predict_fn = jax.jit(predictor.predict)\n",
        "\n",
        "def fixed_predict_fn(sequences: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Wrapper around the predictor `predict` function.\"\"\"\n",
        "    assert sequences.shape[0] == batch_size\n",
        "    return jitted_predict_fn(\n",
        "        params=params,\n",
        "        targets=sequences,\n",
        "        rng=None,\n",
        "    )\n",
        "\n",
        "def predict_fn(sequences: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Wrapper to collate batches of sequences of fixed size.\"\"\"\n",
        "    remainder = -len(sequences) % batch_size\n",
        "    padded = np.pad(sequences, ((0, remainder), (0, 0)))\n",
        "    sequences_split = np.split(padded, len(padded) // batch_size)\n",
        "    all_outputs = []\n",
        "    for sub_sequences in sequences_split:\n",
        "        all_outputs.append(fixed_predict_fn(sub_sequences))\n",
        "    print('sequences.shape[0]:', sequences.shape[0])\n",
        "    return all_outputs[: (sequences.shape[0])] #outputs[: len(sequences)]  # Crop the padded sequences.\n",
        "\n",
        "\n",
        "_, return_buckets_values = utils.get_uniform_buckets_edges_values(\n",
        "    num_return_buckets\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CudaDevice(id=0)]\n"
          ]
        }
      ],
      "source": [
        "# Comprobamos que estemos utilizando JAX con GPU\n",
        "print(jax.devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Par√°metros del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Parametros de 9M:')\n",
        "print(params.keys())\n",
        "print('embed:')\n",
        "print(params['embed'].keys())\n",
        "print(params['embed']['embeddings'].shape)\n",
        "print('embed posicional:')\n",
        "print(params['embed_1'].keys())\n",
        "print(params['embed_1']['embeddings'].shape)\n",
        "print('layer_norm:')\n",
        "print(params['layer_norm'].keys())\n",
        "print(params['layer_norm']['offset'].shape)\n",
        "print(params['layer_norm']['scale'].shape)\n",
        "print('linear:')\n",
        "print(params['linear'].keys())\n",
        "print(params['linear']['w'].shape)\n",
        "print('multi_head_dot_product_attention/linear')\n",
        "print(params['multi_head_dot_product_attention/linear'].keys())\n",
        "print(params['multi_head_dot_product_attention/linear']['w'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Posicional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_labels = ['<start>', '<turn>', \n",
        "            'a8', 'b8', 'c8', 'd8', 'e8', 'f8', 'g8', 'h8',\n",
        "            'a7', 'b7', 'c7', 'd7', 'e7', 'f7', 'g7', 'h7',\n",
        "            'a6', 'b6', 'c6', 'd6', 'e6', 'f6', 'g6', 'h6',\n",
        "            'a5', 'b5', 'c5', 'd5', 'e5', 'f5', 'g5', 'h5',\n",
        "            'a4', 'b4', 'c4', 'd4', 'e4', 'f4', 'g4', 'h4',\n",
        "            'a3', 'b3', 'c3', 'd3', 'e3', 'f3', 'g3', 'h3',\n",
        "            'a2', 'b2', 'c2', 'd2', 'e2', 'f2', 'g2', 'h2',\n",
        "            'a1', 'b1', 'c1', 'd1', 'e1', 'f1', 'g1', 'h1',\n",
        "            '<castling_1>', '<castling_2>', '<castling_3>', '<castling_4>',\n",
        "            '<en_passant_letter>','<en_passant_number>',\n",
        "            '<halfmove_1>', '<halfmove_2>', '<halfmove_3>',\n",
        "            '<fullmove_1>', '<fullmove_2>', '<fullmove_3>', \n",
        "            'move']\n",
        "len(pos_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "plt.imshow(params['embed_1']['embeddings'], aspect='auto', cmap='viridis') \n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Embedding posicional de la entrada')\n",
        "plt.xlabel('Embedding')\n",
        "plt.ylabel('Posiciones')\n",
        "\n",
        "yticks = np.arange(len(pos_labels))\n",
        "yticklabels = pos_labels\n",
        "plt.yticks(ticks=yticks, labels=yticklabels)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular la distancia entre los embeddings de cada token\n",
        "\n",
        "data = params['embed_1']['embeddings']\n",
        "distances_pos_embedding = np.zeros((data.shape[0], data.shape[0]))\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "    if i % 10 == 0:\n",
        "        print(i)\n",
        "    for j in range(i+1, data.shape[0]):\n",
        "        distances_pos_embedding[i,j] = np.linalg.norm(data[i] - data[j])\n",
        "        \n",
        "for i in range(data.shape[0]):\n",
        "    for j in range(i+1):\n",
        "        distances_pos_embedding[i,j] = distances_pos_embedding[j,i]\n",
        "#np.save('distances_between_pos_embeddings.npy', distances_pos_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear el mapa de calor con las distancias entre embeddings\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(distances_pos_embedding, aspect='auto', cmap='viridis')  \n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Distancias entre embeddings de posici√≥n')\n",
        "plt.xlabel('Eje X')\n",
        "plt.ylabel('Eje Y')\n",
        "\n",
        "yticks = np.arange(len(pos_labels))\n",
        "yticklabels = pos_labels\n",
        "plt.yticks(ticks=yticks, labels=yticklabels)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_ini = 2\n",
        "pos_fin = 66\n",
        "distancias_tablero = distances_pos_embedding[pos_ini:pos_fin,pos_ini:pos_fin]\n",
        "\n",
        "# Crear figura con 8x8 subplots\n",
        "fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
        "\n",
        "# Iterar sobre cada bloque 8x8\n",
        "for i in range(8):\n",
        "    for j in range(8):\n",
        "        pos_actual = i*8 + j\n",
        "        block = distancias_tablero[i*8 + j].reshape(8, 8)\n",
        "        ax = axes[i, j]\n",
        "        im = ax.imshow(block, cmap='viridis')\n",
        "        ax.axis('off')\n",
        "        \n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Vocabulario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creamos un diccionario para saber qu√© significa cada token\n",
        "from collections import defaultdict\n",
        "\n",
        "y_labels_dict = defaultdict(list)\n",
        "\n",
        "for i in range(len(utils.ACTION_TO_MOVE.items())):\n",
        "    y_labels_dict[i] = [str(i)]\n",
        "    \n",
        "# Mezclamos el primer diccionario\n",
        "for v, k in tokenizer._CHARACTERS_INDEX.items():\n",
        "    y_labels_dict[k].append(v)\n",
        "    \n",
        "# Mezclamos el segundo diccionario (invertido del tokenizer)\n",
        "for k, v in utils.ACTION_TO_MOVE.items():\n",
        "    y_labels_dict[k].append(v)\n",
        "\n",
        "# Convertimos de nuevo a un diccionario normal (opcional)\n",
        "y_labels_dict = {k: '/'.join(v) for k, v in y_labels_dict.items()}\n",
        "\n",
        "print(y_labels_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graficamos los embeddings de los tokens\n",
        "num_rows = 50\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(params['embed']['embeddings'][:num_rows, :], aspect='auto', cmap='viridis')\n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Embedding del vocabulario')\n",
        "plt.xlabel('Eje X')\n",
        "plt.ylabel('Eje Y')\n",
        "\n",
        "# Asignar etiquetas al eje Y\n",
        "yticks = list(y_labels_dict.keys())[:num_rows]\n",
        "yticklabels = list(y_labels_dict.values())[:num_rows]\n",
        "plt.yticks(ticks=yticks, labels=yticklabels)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear un array de ejemplo de tama√±o 79x256\n",
        "data = params['embed']['embeddings'][:256,:]\n",
        "\n",
        "# Crear el mapa de calor\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(data, aspect='auto', cmap='viridis')  # Puedes usar otros cmap como 'plasma', 'hot', 'coolwarm'\n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Embedding del vocabulario')\n",
        "plt.xlabel('Eje X')\n",
        "plt.ylabel('Eje Y')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IDEA: Extraer solo embeddings de piezas o posiciones y ver si tienen caracter√≠sticas en com√∫n\n",
        "# En qu√© se diferencian los embeddings de la misma pieza seg√∫n el color?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(params['embed']['embeddings'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular la distancia entre los embeddings de cada token\n",
        "\"\"\"\n",
        "data = params['embed']['embeddings']\n",
        "distances = np.zeros((data.shape[0], data.shape[0]))\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "    if i % 10 == 0:\n",
        "        print(i)\n",
        "    for j in range(i+1, data.shape[0]):\n",
        "        distances[i,j] = np.linalg.norm(data[i] - data[j])\n",
        "        \n",
        "for i in range(data.shape[0]):\n",
        "    for j in range(i+1):\n",
        "        distances[i,j] = distances[j,i]\n",
        "np.save('distances_between_token_embeddings.npy', distances)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "distances = np.load('distances_between_token_embeddings.npy')\n",
        "distances.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleccionamos las posiciones donde estan las piezas\n",
        "pos_b = 11\n",
        "pos_ini_piezas = 19\n",
        "pos_fin_piezas = 29\n",
        "pos_point = 30\n",
        "\n",
        "is_pieza = np.zeros((distances.shape[0],), dtype=bool)\n",
        "is_pieza[pos_b] = 1\n",
        "is_pieza[pos_ini_piezas:pos_fin_piezas] = 1\n",
        "is_pieza[pos_point] = 1\n",
        "print(is_pieza)\n",
        "\n",
        "distances_piezas = distances[np.ix_(is_pieza, is_pieza)]\n",
        "\n",
        "\n",
        "# Crear el mapa de calor con las distancias entre embeddings\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(distances_piezas, aspect='auto', cmap='viridis') \n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Distancias entre embeddings de piezas')\n",
        "plt.xlabel('Eje X')\n",
        "plt.ylabel('Eje Y')\n",
        "\n",
        "# Asignar etiquetas a los ejes\n",
        "ticklabels = [y_labels_dict[k] for k in np.argwhere(is_pieza == 1).flatten()]\n",
        "ticks = np.arange(len(ticklabels))\n",
        "print(ticklabels)\n",
        "plt.xticks(ticks=ticks, labels=ticklabels, rotation=90)\n",
        "plt.yticks(ticks=ticks, labels=ticklabels)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fila_inicial = 0\n",
        "fila_final = 50\n",
        "# Crear el mapa de calor con las distancias entre embeddings\n",
        "plt.figure(figsize=(12, 12))\n",
        "plt.imshow(distances[fila_inicial:fila_final,fila_inicial:fila_final], aspect='auto', cmap='viridis')  # Puedes usar otros cmap como 'plasma', 'hot', 'coolwarm'\n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Distancias entre embeddings de diferente tipo')\n",
        "plt.xlabel('Eje X')\n",
        "plt.ylabel('Eje Y')\n",
        "\n",
        "# Asignar etiquetas a los ejes\n",
        "ticks = list(range(fila_final-fila_inicial))\n",
        "ticklabels = list(y_labels_dict.values())[fila_inicial:fila_final]\n",
        "plt.xticks(ticks=ticks, labels=ticklabels, rotation=90)\n",
        "plt.yticks(ticks=ticks, labels=ticklabels)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for items in utils.MOVE_TO_ACTION.items():\n",
        "    print(items[0], items[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fila_inicial = 0\n",
        "fila_final = 400\n",
        "# Crear el mapa de calor con las distancias entre embeddings\n",
        "plt.figure(figsize=(35, 35))\n",
        "plt.imshow(distances[fila_inicial:fila_final,fila_inicial:fila_final], aspect='auto', cmap='viridis')  # Puedes usar otros cmap como 'plasma', 'hot', 'coolwarm'\n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Distancias entre embeddings de piezas')\n",
        "plt.xlabel('Eje X')\n",
        "plt.ylabel('Eje Y')\n",
        "\n",
        "# Asignar etiquetas a los ejes\n",
        "ticks = list(range(fila_final-fila_inicial))\n",
        "ticklabels = list(y_labels_dict.values())[fila_inicial:fila_final]\n",
        "plt.xticks(ticks=ticks, labels=ticklabels, rotation=90)\n",
        "plt.yticks(ticks=ticks, labels=ticklabels)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fila_inicial = 739\n",
        "fila_final = 842\n",
        "# Crear el mapa de calor con las distancias entre embeddings\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(distances[fila_inicial:fila_final,fila_inicial:fila_final], aspect='auto', cmap='viridis')  # Puedes usar otros cmap como 'plasma', 'hot', 'coolwarm'\n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Distancias entre embeddings de piezas')\n",
        "plt.xlabel('Eje X')\n",
        "plt.ylabel('Eje Y')\n",
        "\n",
        "# Asignar etiquetas a los ejes\n",
        "ticks = list(range(fila_final-fila_inicial))\n",
        "ticklabels = list(y_labels_dict.values())[fila_inicial:fila_final]\n",
        "plt.xticks(ticks=ticks, labels=ticklabels, rotation=90)\n",
        "plt.yticks(ticks=ticks, labels=ticklabels)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear el mapa de calor con las distancias entre embeddings\n",
        "plt.figure(figsize=(30, 30))\n",
        "plt.imshow(distances, aspect='auto', cmap='viridis')  # Puedes usar otros cmap como 'plasma', 'hot', 'coolwarm'\n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Distancias entre embeddings de piezas')\n",
        "plt.xlabel('Eje X')\n",
        "plt.ylabel('Eje Y')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fila_inicial = 1792\n",
        "fila_final = 1967\n",
        "# Crear el mapa de calor con las distancias entre embeddings\n",
        "plt.figure(figsize=(24, 24))\n",
        "plt.imshow(distances[fila_inicial:fila_final,fila_inicial:fila_final], aspect='auto', cmap='viridis')  # Puedes usar otros cmap como 'plasma', 'hot', 'coolwarm'\n",
        "plt.colorbar(label='Valor')\n",
        "plt.title('Distancias entre embeddings de piezas')\n",
        "plt.xlabel('Eje X')\n",
        "plt.ylabel('Eje Y')\n",
        "\n",
        "# Asignar etiquetas a los ejes\n",
        "ticks = list(range(fila_final-fila_inicial))\n",
        "ticklabels = list(y_labels_dict.values())[fila_inicial:fila_final]\n",
        "plt.xticks(ticks=ticks, labels=ticklabels, rotation=90)\n",
        "plt.yticks(ticks=ticks, labels=ticklabels)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Obtenemos los logits y graficamos los mapas de atenci√≥n\n",
        "for result, move in zip(results, engine.get_ordered_legal_moves(board)):\n",
        "    print('Jugada:', move)\n",
        "    logits, attention_maps = result\n",
        "    print('logits:', logits.shape)\n",
        "    print('logits:', logits)\n",
        "    plot_attention_maps(attention_maps, token_labels=token_labels, save_path=f'xai/experiment1/79x79/attention_maps_{move}.png')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Obtenemos los logits y graficamos los mapas de atenci√≥n\n",
        "os.makedirs(f'xai/experiment1/reordered_by_row', exist_ok=True)\n",
        "os.makedirs(f'xai/experiment1/reordered_by_col', exist_ok=True)\n",
        "for result, move in zip(results, engine.get_ordered_legal_moves(board)):\n",
        "    for by_row in [True, False]:\n",
        "        print('Jugada:', move)\n",
        "        logits, attention_maps = result\n",
        "        attention_maps = np.array(attention_maps).reshape(num_layers, num_heads, 79, 79)\n",
        "        #print('logits:', logits.shape)\n",
        "        print('logits:', logits)\n",
        "        plot_all_attention_heads(attention_maps, token_labels=token_labels, by_row=by_row,\n",
        "                            save_path=f'xai/experiment1/reordered_{\"by_row\" if by_row else \"by_col\"}/attention_maps_{move}.png')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardamos los resultados en disco\n",
        "\"\"\"\n",
        "with open('xai/experiment1/results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Atenci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pesos de atenci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "token_labels = ['<start>', '<turn>',\n",
        "                'a8', 'b8', 'c8', 'd8', 'e8', 'f8', 'g8', 'h8',\n",
        "                'a7', 'b7', 'c7', 'd7', 'e7', 'f7', 'g7', 'h7',\n",
        "                'a6', 'b6', 'c6', 'd6', 'e6', 'f6', 'g6', 'h6',\n",
        "                'a5', 'b5', 'c5', 'd5', 'e5', 'f5', 'g5', 'h5',\n",
        "                'a4', 'b4', 'c4', 'd4', 'e4', 'f4', 'g4', 'h4',\n",
        "                'a3', 'b3', 'c3', 'd3', 'e3', 'f3', 'g3', 'h3',\n",
        "                'a2', 'b2', 'c2', 'd2', 'e2', 'f2', 'g2', 'h2',\n",
        "                'a1', 'b1', 'c1', 'd1', 'e1', 'f1', 'g1', 'h1',\n",
        "                '<castling_1>', '<castling_2>', '<castling_3>', '<castling_4>',\n",
        "                '<en_passant_letter>','<en_passant_number>',\n",
        "                '<halfmove_1>', '<halfmove_2>', '<halfmove_3>',\n",
        "                '<fullmove_1>', '<fullmove_2>', '<fullmove_3>', \n",
        "                'move']\n",
        "token_labels = np.array(token_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_sequences_from_board(board: chess.Board) -> np.ndarray:\n",
        "    \"\"\"Get the sequences from a chess board.\"\"\"\n",
        "    sorted_legal_moves = engine.get_ordered_legal_moves(board)\n",
        "    #print('sorted_legal_moves:', sorted_legal_moves)\n",
        "    legal_actions = [utils.MOVE_TO_ACTION[x.uci()] for x in sorted_legal_moves]\n",
        "    #print('legal_actions 1:', legal_actions)\n",
        "    legal_actions = np.array(legal_actions, dtype=np.int32)\n",
        "    #print('legal_actions 2:', legal_actions)\n",
        "    legal_actions = np.expand_dims(legal_actions, axis=-1)\n",
        "    #print('legal_actions 3:', legal_actions)\n",
        "    #print('legal_actions.shape:', legal_actions.shape)\n",
        "    # Tokenize the return buckets.\n",
        "    dummy_return_buckets = np.zeros((len(legal_actions), 1), dtype=np.int32)\n",
        "    #print('dummy_return_buckets:', dummy_return_buckets)\n",
        "    #print('dummy_return_buckets.shape:', dummy_return_buckets.shape)\n",
        "    # Tokenize the board.\n",
        "    tokenized_fen = tokenizer.tokenize(board.fen()).astype(np.int32)\n",
        "    #print('tokenized_fen:', tokenized_fen)\n",
        "    #print('tokenized_fen.shape:', tokenized_fen.shape)\n",
        "    sequences = np.stack([tokenized_fen] * len(legal_actions))\n",
        "    #print('sequences:', sequences)\n",
        "    #print('sequences.shape:', sequences.shape)\n",
        "    # Create the sequences.\n",
        "    sequences = np.concatenate(\n",
        "        [sequences, legal_actions, dummy_return_buckets],\n",
        "        axis=1,\n",
        "    )\n",
        "    return sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_attention_maps(attention_maps, token_labels=None, save_path=None):\n",
        "    \"\"\"\n",
        "    attention_maps: List of jax arrays [B, H, T, T], one per layer.\n",
        "    token_labels: Optional list of labels for tokens.\n",
        "    \"\"\"\n",
        "    num_layers, num_heads, seq_len, _ = attention_maps.shape\n",
        "\n",
        "    fig, axs = plt.subplots(num_layers, num_heads, figsize=(num_heads*8, num_layers*8))\n",
        "\n",
        "    for l, layer_attn in enumerate(attention_maps):\n",
        "        for h in range(num_heads):\n",
        "            ax = axs[l, h] if num_layers > 1 else axs[h]\n",
        "            attn = np.array(layer_attn[h])  # (T, T)\n",
        "            im = ax.imshow(attn, cmap=\"viridis\")\n",
        "            ax.set_title(f\"L{l+1}H{h+1}\", fontsize=8)\n",
        "            if token_labels is not None:\n",
        "                ax.set_xticks(range(seq_len))\n",
        "                ax.set_yticks(range(seq_len))\n",
        "                ax.set_xticklabels(token_labels, rotation=90)\n",
        "                ax.set_yticklabels(token_labels)\n",
        "            else:\n",
        "                ax.set_xticks([])\n",
        "                ax.set_yticks([])\n",
        "\n",
        "    fig.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_attention_in_board(attention_map, by_row = True, token_labels=None, save_path=None):\n",
        "    \"\"\"\n",
        "    attention_maps: List of jax arrays [B, H, T, T], one per layer.\n",
        "    token_labels: Optional list of labels for tokens.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(nrows=10, ncols=8, figsize=(16, 20))\n",
        "    axes = axes.flatten()  # Para iterar f√°cilmente\n",
        "    \n",
        "    padded_attention_map = np.pad(attention_map, ((0, 1), (0, 1)), mode='constant', constant_values=0)\n",
        "    \n",
        "    ordered_indices = np.arange(2, 66)\n",
        "    ordered_indices = np.concatenate((ordered_indices, [0, 1]))\n",
        "    ordered_indices = np.concatenate((ordered_indices, np.arange(66, 79)))\n",
        "    ordered_indices_padded = np.concatenate((ordered_indices, [79]))\n",
        "    \n",
        "    # Dibujar cada fila como heatmap en su subplot correspondiente\n",
        "    for i,j in zip(ordered_indices, range(79)): \n",
        "        ax = axes[j]\n",
        "        if by_row:\n",
        "            row_data = padded_attention_map[i,ordered_indices_padded].reshape(-1, 8)  # Mantenerlo 2D\n",
        "        else:\n",
        "            row_data = padded_attention_map[ordered_indices_padded,i].reshape(-1, 8)\n",
        "        im = ax.imshow(row_data, aspect='auto', cmap='viridis')\n",
        "        if j < 64:\n",
        "            ax.set_title(token_labels[i-1])\n",
        "        else:\n",
        "            ax.set_title(token_labels[i])\n",
        "        \n",
        "        if j % 8 == 0:  # Primera columna\n",
        "            ax.set_yticks(range(10))\n",
        "            ax.set_yticklabels(token_labels[ordered_indices][::8])\n",
        "        else:\n",
        "            ax.set_yticks([])\n",
        "        ax.set_xticks([])\n",
        "        ax.set_xticklabels([])\n",
        "        #ax.set_yticklabels(token_labels[ordered_indices].astype(int)[::8])\n",
        "            \n",
        "        #ax.axis('off')\n",
        "    \n",
        "    # Ocultar el subplot sobrante (posici√≥n 80)\n",
        "    axes[79].axis('off')\n",
        "\n",
        "    # Agregar barra de color a la derecha de todos los subgr√°ficos\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    #fig.colorbar(im, ax=axes.tolist(), shrink=0.6)\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_attention_in_board_embedded(attention_map, token_labels, fig, subplot_spec, by_row=True, vmin=None, vmax=None):\n",
        "    \"\"\"\n",
        "    attention_map: numpy array [79, 79]\n",
        "    token_labels: list of token strings\n",
        "    fig: Matplotlib figure\n",
        "    subplot_spec: GridSpec SubplotSpec to draw the board into\n",
        "    use_divergent_cmap: bool - whether to use a divergent colormap centered at 0\n",
        "    \"\"\"\n",
        "    gs = gridspec.GridSpecFromSubplotSpec(10, 8, subplot_spec=subplot_spec, wspace=0.5, hspace=0.5)\n",
        "    padded_attention_map = np.pad(attention_map, ((0, 1), (0, 1)), mode='constant', constant_values=0)\n",
        "    ordered_indices = np.concatenate([np.arange(2, 66), [0, 1], np.arange(66, 79)])\n",
        "    ordered_indices_padded = np.concatenate([ordered_indices, [79]])\n",
        "\n",
        "    ordered_token_labels = token_labels[ordered_indices]\n",
        "\n",
        "    for idx, i in enumerate(ordered_indices):\n",
        "        row = idx // 8\n",
        "        col = idx % 8\n",
        "        ax = fig.add_subplot(gs[row, col])\n",
        "        if by_row:\n",
        "            data = padded_attention_map[i, ordered_indices_padded].reshape(-1, 8)\n",
        "        else:\n",
        "            data = padded_attention_map[ordered_indices_padded, i].reshape(-1, 8)\n",
        "\n",
        "        if vmin is not None and vmax is not None:\n",
        "            im = ax.imshow(data, aspect='auto', cmap='seismic', vmin=vmin, vmax=vmax)\n",
        "        else:\n",
        "            im = ax.imshow(data, aspect='auto', cmap='viridis')\n",
        "\n",
        "        ax.set_title(ordered_token_labels[idx], fontsize=6)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    fig.add_subplot(gs[-1, -1]).axis('off')  # Oculta el subplot extra\n",
        "\n",
        "def plot_all_attention_heads(attention_maps, token_labels, by_row=True, save_path=None, scale_in_1=True):\n",
        "    \"\"\"\n",
        "    attention_maps: numpy array of shape (4, 4, 79, 79)\n",
        "    token_labels: list of token strings\n",
        "    use_divergent_cmap: bool - whether to use a divergent colormap for all heatmaps\n",
        "    \"\"\"\n",
        "    num_layers, num_heads, _, _ = attention_maps.shape\n",
        "    fig = plt.figure(figsize=(num_heads * 10, num_layers * 10))\n",
        "    outer = gridspec.GridSpec(num_layers, num_heads, wspace=0.1, hspace=0.1)\n",
        "\n",
        "    for l in range(num_layers):\n",
        "        for h in range(num_heads):\n",
        "            attention_map = attention_maps[l, h]\n",
        "            subplot_spec = outer[l, h]\n",
        "            if scale_in_1:\n",
        "                plot_attention_in_board_embedded(\n",
        "                    attention_map,\n",
        "                    token_labels,\n",
        "                    fig,\n",
        "                    subplot_spec,\n",
        "                    by_row=by_row,\n",
        "                    vmin=-1,\n",
        "                    vmax=1\n",
        "                )\n",
        "            else:\n",
        "                plot_attention_in_board_embedded(\n",
        "                    attention_map,\n",
        "                    token_labels,\n",
        "                    fig,\n",
        "                    subplot_spec,\n",
        "                    by_row=by_row\n",
        "                )\n",
        "            ax = fig.add_subplot(subplot_spec)\n",
        "            ax.set_title(f\"Capa {l+1}, Cabeza {h+1}\", fontsize=10)\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        plt.close(fig)\n",
        "    else:\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board = chess.Board()\n",
        "sequences = get_sequences_from_board(board)\n",
        "print(sequences.shape)\n",
        "results = predict_fn(sequences)\n",
        "print(results)\n",
        "logits, attention_maps = results[0]\n",
        "print(np.array(logits).shape)\n",
        "print(np.array(attention_maps).shape)\n",
        "attention_maps = np.array(attention_maps).reshape(num_layers, num_heads, 79, 79)\n",
        "print('results:', logits.shape)\n",
        "print('attention_maps_shape:', attention_maps.shape)\n",
        "plot_attention_maps(attention_maps, token_labels=token_labels)\n",
        "plot_all_attention_heads(attention_maps, token_labels=token_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attention Rollout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def attention_rollout(attention_maps, alpha=0.5):\n",
        "    \"\"\"\n",
        "    attention_maps: numpy array of shape (num_layers, num_heads, seq_len, seq_len)\n",
        "    alpha: float - smoothing factor\n",
        "    \"\"\"\n",
        "    num_layers, num_heads, seq_len, _ = attention_maps.shape\n",
        "    \n",
        "    # Calculamos los mapas de atenci√≥n medios por capa\n",
        "    aggregated_attention = np.zeros((num_layers, seq_len, seq_len))\n",
        "    for l in range(num_layers):\n",
        "        aggregated_attention[l] = np.mean(attention_maps[l], axis=0)  # Media entre cabezas de atenci√≥n\n",
        "    \n",
        "    # A√±adimos la influencia de las capas residuales\n",
        "    for l in range(1, num_layers):\n",
        "        aggregated_attention[l] = aggregated_attention[l] * alpha + np.diag(np.ones(seq_len)) * (1 - alpha) \n",
        "        \n",
        "    # Calculamos el atention rollout de las capas\n",
        "    attention_rollout = np.zeros((num_layers, seq_len, seq_len))\n",
        "\n",
        "    attention_rollout[0] = aggregated_attention[0]\n",
        "    for l in range(1,num_layers):\n",
        "        attention_rollout[l] = aggregated_attention[l] @ attention_rollout[l-1]\n",
        "\n",
        "    return attention_rollout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board = chess.Board('1k6/8/8/8/8/8/7P/1K6 w - - 0 1')\n",
        "sequences = get_sequences_from_board(board)\n",
        "print(sequences.shape)\n",
        "results = predict_fn(sequences)\n",
        "logits, attention_maps = results[0]\n",
        "attention_maps = np.array(attention_maps).reshape(num_layers, num_heads, 79, 79)\n",
        "print('results:', logits.shape)\n",
        "print('attention_maps_shape:', attention_maps.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_rollout_maps = attention_rollout(attention_maps, alpha=0.5)\n",
        "\n",
        "plot_all_attention_heads(attention_rollout_maps.reshape(1,-1,79,79), token_labels=token_labels, scale_in_1=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Attention flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_attention_graph(attention_maps, alpha = 0.5):\n",
        "    mat = attention_maps.mean(axis=1)\n",
        "    n_layers, length, _ = mat.shape\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    for i in range(1, n_layers + 1):\n",
        "        for k_f in range(length):\n",
        "            index_from = (i,k_f)\n",
        "            for k_t in range(length):\n",
        "                index_to = (i - 1, k_t)\n",
        "                weight = mat[i - 1][k_f][k_t]\n",
        "                weight += 0.5 if k_f == k_t else 0\n",
        "                if weight != 0:\n",
        "                    G.add_edge(index_from, index_to, capacity=weight)\n",
        "\n",
        "    return G        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# Implementaci√≥n original de attention_flow (ineficiente - O(n^4*d^2) - n = seq_len, d = embedding_dim\n",
        "def compute_flows(attention_maps):\n",
        "    n_layers, _, length, _ = attention_maps.shape\n",
        "    G = get_attention_graph(attention_maps)\n",
        "    \n",
        "    flow_values=np.zeros((length, length))\n",
        "    for i in range(length):\n",
        "        u = (n_layers, i)\n",
        "        for j in range(length):\n",
        "            v = (0, j)\n",
        "            try:\n",
        "                flow, _  = nx.maximum_flow(G, u, v)\n",
        "            except nx.NetworkXUnfeasible:\n",
        "                flow = 0.0  # si no hay camino posible\n",
        "            flow_values[i, j] = flow\n",
        "    \n",
        "    # Normalizaci√≥n fila por fila (por nodo de salida)\n",
        "    row_sums = flow_values.sum(axis=1, keepdims=True)\n",
        "    row_sums[row_sums == 0] = 1  # evita divisi√≥n por cero\n",
        "    flow_values /= row_sums\n",
        "    \n",
        "    return flow_values\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_attention_flow(attn_weights: np.ndarray, sink_token, source_layer = None) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Calcula el flujo m√°ximo de atenci√≥n desde todos los token de salida \n",
        "    hacia el token de entrada sink_token a trav√©s del grafo de atenci√≥n.\n",
        "    \n",
        "    Par√°metros:\n",
        "        attn_weights: np.ndarray con forma (num_layers, num_heads, seq_len, seq_len)\n",
        "                      Representa atenci√≥n desde tokens de capa l-1 a tokens de capa l.\n",
        "        source_token: √≠ndice del token en la capa final desde donde fluye la atenci√≥n (e.g., [CLS]=0)\n",
        "    \n",
        "    Retorna:\n",
        "        flow_to_inputs: np.ndarray con forma (seq_len,)\n",
        "                        Cantidad de atenci√≥n que fluye desde el token origen a cada token de entrada.\n",
        "    \"\"\"\n",
        "    \n",
        "    num_layers, _, seq_len, _ = attn_weights.shape\n",
        "    if source_layer is None:\n",
        "        source_layer = num_layers\n",
        "    G = get_attention_graph(attn_weights)\n",
        "\n",
        "    sink = (0, sink_token)\n",
        "    supersource = \"supersource\"\n",
        "    for t in range(seq_len):\n",
        "        G.add_edge(supersource, (source_layer, t), capacity=float('inf'))\n",
        "    \n",
        "    flow_value = nx.maximum_flow_value(G, supersource, sink)\n",
        "    \n",
        "    return flow_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def plot_attention_flow_heatmap(attention_flow_vals, token_labels, save_path=None):\n",
        "    \"\"\"\n",
        "    Plotea el flujo de atenci√≥n como un heatmap con las etiquetas de tokens dentro de cada celda.\n",
        "    \n",
        "    Par√°metros:\n",
        "        attention_flow_vals: np.ndarray de forma (seq_len,)\n",
        "                             Valores de flujo de atenci√≥n por token.\n",
        "        token_labels: np.ndarray o lista de strings de longitud seq_len\n",
        "                      Etiquetas de los tokens.\n",
        "    \"\"\"\n",
        "    # Padding para completar 80 posiciones\n",
        "    padded_attention_map = np.concatenate((attention_flow_vals, [0]), axis=0)\n",
        "    ordered_indices = np.concatenate([np.arange(2, 66), [0, 1], np.arange(66, 79)])\n",
        "    ordered_indices_padded = np.concatenate([ordered_indices, [79]])\n",
        "    \n",
        "    # Reordenar etiquetas\n",
        "    ordered_token_labels = np.array(token_labels)[ordered_indices]\n",
        "\n",
        "    # Preparar datos en forma de matriz (10x8)\n",
        "    data = padded_attention_map[ordered_indices_padded].reshape(-1, 8)\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    im = plt.imshow(data, aspect='auto', cmap='viridis')\n",
        "\n",
        "    # A√±adir las etiquetas dentro de las celdas\n",
        "    for i in range(data.shape[0]):\n",
        "        for j in range(data.shape[1]):\n",
        "            idx = i * 8 + j\n",
        "            if idx < len(ordered_token_labels):\n",
        "                plt.text(j, i, ordered_token_labels[idx], \n",
        "                         ha='center', va='center', fontsize=7, color='white')\n",
        "\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.colorbar(im, label='Attention Flow Value')\n",
        "    plt.title(\"Attention Flow Heatmap\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_flow_vals = np.zeros((79,))\n",
        "for i in range(79):\n",
        "    if i % 10 == 0:\n",
        "        print(i)\n",
        "    attention_flow_vals[i] = compute_attention_flow(attention_maps, sink_token=i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_attention_flow_heatmap(attention_flow_vals, token_labels=token_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gradientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_token_grad_importance(\n",
        "    predictor,      # constants.Predictor\n",
        "    params,         # par√°metros cargados\n",
        "    input_seq,      # np.array shape (1, T) con √≠ndices de tokens\n",
        "    config          # TransformerConfig\n",
        "):\n",
        "    \"\"\"\n",
        "    Calcula la relevancia (gradientes) de cada token de entrada usando override_embedding.\n",
        "\n",
        "    Returns:\n",
        "      importances: np.array shape (T,) con la derivada del log-prob del token objetivo.\n",
        "    \"\"\"\n",
        "    # Dimensiones\n",
        "    T = input_seq.shape[0]\n",
        "    V = config.vocab_size\n",
        "\n",
        "    # 1) Extrae la matriz de embeddings de params\n",
        "    tok_emb_matrix = params['embed']['embeddings']\n",
        "    pos_emb_matrix = params['embed_1']['embeddings']\n",
        "\n",
        "    # 2) Construye un one-hot ‚Äúsuave‚Äù de tu secuencia\n",
        "    inputs_shifted = transformer_xai.shift_right(input_seq.reshape(1,-1))  # shape (1, T)\n",
        "    one_hot = jax.nn.one_hot(inputs_shifted, V)  # (1, T, V)\n",
        "\n",
        "    # 3) Define la funci√≥n de p√©rdida sobre el one-hot continuo\n",
        "    def loss_fn(one_hot_cont):\n",
        "        # 1) Proyecci√≥n one-hot ‚Üí embeddings\n",
        "        token_emb = jnp.einsum('b t v, v d -> b t d', one_hot_cont, tok_emb_matrix)\n",
        "        pos_emb = jnp.broadcast_to(pos_emb_matrix[None, :, :], token_emb.shape)\n",
        "        final_emb = token_emb + pos_emb\n",
        "        \n",
        "        # 2) Inferencia override\n",
        "        buckets_logp, _ = predictor.predict(\n",
        "            params=params,\n",
        "            targets=final_emb,\n",
        "            rng=None,\n",
        "            override_embedding=True,\n",
        "            config=config,\n",
        "        )\n",
        "        # buckets_logp: (1, T, V)\n",
        "        last_logp = buckets_logp[0, -1, :]        # (V,)\n",
        "        \n",
        "        # 3) convierte a probabilidades y calcula probabilidad de victoria\n",
        "        probs = jnp.exp(last_logp)                # (V,)\n",
        "        win_prob = jnp.dot(probs, return_buckets_values)  # escalar ()\n",
        "\n",
        "        # Queremos maximizar win_prob, as√≠ que la \"p√©rdida\" la tomamos como -win_prob\n",
        "        return -win_prob\n",
        "\n",
        "\n",
        "    # 4) Gradiente del escalar respecto al one-hot continuo\n",
        "    grad_fn = jax.grad(loss_fn)\n",
        "    grads = grad_fn(one_hot)               # (1, T, V)\n",
        "    jacc_fn = jax.grad(lambda x: jax.grad(loss_fn)(x).sum())\n",
        "    jacc = jacc_fn(one_hot)                # (1, T, V)\n",
        "    # 5) Para cada posici√≥n t, tomamos la componente del token real\n",
        "    \n",
        "    gradients = grads[0, jnp.arange(T), input_seq]  # (T,)\n",
        "    jacobians = jacc[0, jnp.arange(T), input_seq]  # (T,)\n",
        "\n",
        "    return np.array(gradients), np.array(jacobians)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Plot the attention maps\n",
        "# Sup√≥n que ya has calculado:\n",
        "# importances: numpy array de shape (T,) con la relevancia de cada token\n",
        "# feature_names: lista de strings de longitud T con nombres legibles de cada token\n",
        "\n",
        "def bar_plot_token_importances(importances: np.ndarray, token_labels: list[str],\n",
        "                           save_path: str = None):\n",
        "    \"\"\"\n",
        "    Grafica un bar chart mostrando la importancia de cada token.\n",
        "    - importances: array de shape (T,) con relevancias.\n",
        "    - feature_names: lista de longitud T con etiquetas para cada token.\n",
        "    \"\"\"\n",
        "    T = len(importances)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.bar(range(T), importances)\n",
        "    plt.xticks(range(T), token_labels, rotation=90)\n",
        "    plt.xlabel(\"Token\")\n",
        "    plt.ylabel(\"Importancia (gradiente)\")\n",
        "    plt.title(\"Importancia de cada token en la predicci√≥n\")\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "def board_plot_token_importances(\n",
        "    importances: np.ndarray,\n",
        "    token_labels: list[str],\n",
        "    save_path: str = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Grafica un mapa de calor mostrando la importancia de cada token.\n",
        "    - importances: array de shape (T,) con relevancias.\n",
        "    - feature_names: lista de longitud T con etiquetas para cada token.\n",
        "    \"\"\"\n",
        "    padded_importances = np.concatenate((importances, [0]))\n",
        "    ordered_indices = np.concatenate([np.arange(2, 66), [0, 1], np.arange(66, 79)])\n",
        "    ordered_indices_padded = np.concatenate([ordered_indices, [79]])\n",
        "    padded_token_labels = np.concatenate([token_labels, ['pad']])\n",
        "    ordered_token_labels = padded_token_labels[ordered_indices_padded].reshape(-1, 8)\n",
        "    boarded_importances = padded_importances[ordered_indices_padded].reshape(-1, 8)\n",
        "    \n",
        "    plt.figure(figsize=(8, 10))\n",
        "    vmin, vmax = -np.max(np.abs(importances)), np.max(np.abs(importances))\n",
        "\n",
        "    norm = colors.TwoSlopeNorm(vmin=vmin, vcenter=0.0, vmax=vmax)\n",
        "\n",
        "    \n",
        "    im = plt.imshow(boarded_importances, aspect='auto', cmap='coolwarm', norm=norm)\n",
        "    plt.title(\"Importancia de cada token en la predicci√≥n\")\n",
        "    \"\"\"\n",
        "    plt.xticks(range(8), ordered_token_labels[:8], rotation=90)\n",
        "    plt.yticks(range(10), ordered_token_labels[::8])\n",
        "    \"\"\"\n",
        "    for i in range(10):\n",
        "        for j in range(8):\n",
        "            label = ordered_token_labels[i, j]\n",
        "            plt.text(j, i, label, ha='center', va='center', color='white', fontsize=7)\n",
        "\n",
        "    plt.colorbar(label='Importancia')\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prueba:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board = chess.Board()\n",
        "sequences = get_sequences_from_board(board)\n",
        "input_seq = sequences[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gradients, jacobians = compute_token_grad_importance(\n",
        "    predictor,     \n",
        "    params,        \n",
        "    input_seq,     \n",
        "    predictor_config     \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bar_plot_token_importances(gradients, token_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bar_plot_token_importances(jacobians, token_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board_plot_token_importances(gradients, token_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board_plot_token_importances(jacobians, token_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explicadores agn√≥sticos al modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_labels = ['<turn>',\n",
        "            'a8', 'b8', 'c8', 'd8', 'e8', 'f8', 'g8', 'h8',\n",
        "            'a7', 'b7', 'c7', 'd7', 'e7', 'f7', 'g7', 'h7',\n",
        "            'a6', 'b6', 'c6', 'd6', 'e6', 'f6', 'g6', 'h6',\n",
        "            'a5', 'b5', 'c5', 'd5', 'e5', 'f5', 'g5', 'h5',\n",
        "            'a4', 'b4', 'c4', 'd4', 'e4', 'f4', 'g4', 'h4',\n",
        "            'a3', 'b3', 'c3', 'd3', 'e3', 'f3', 'g3', 'h3',\n",
        "            'a2', 'b2', 'c2', 'd2', 'e2', 'f2', 'g2', 'h2',\n",
        "            'a1', 'b1', 'c1', 'd1', 'e1', 'f1', 'g1', 'h1',\n",
        "            '<castling_1>', '<castling_2>', '<castling_3>', 'castling_4>',\n",
        "            '<en_passant_letter>','<en_passant_number>',\n",
        "            '<halfmove_1>', '<halfmove_2>', '<halfmove_3>',\n",
        "            '<fullmove_1>', '<fullmove_2>', '<fullmove_3>', \n",
        "            'move', 'padding']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_fn_xai(input_array):\n",
        "    \"\"\"\n",
        "    input_array: np.array of shape (n_samples, 79)\n",
        "    returns: np.array of shape (n_samples, 1)\n",
        "    \"\"\"\n",
        "    input_array = input_array.astype(np.int32)\n",
        "    results = predict_fn(input_array)\n",
        "    logits = np.array([log[:,-1,:] for log, att in results]).reshape(-1,128)\n",
        "    win_probs = np.inner(np.exp(logits), return_buckets_values)\n",
        "    print('win_probs:', win_probs.shape)\n",
        "    num_returns = input_array.shape[0]\n",
        "    if num_returns == 1:\n",
        "        return np.array([win_probs[0]])\n",
        "    else:\n",
        "        return win_probs[:input_array.shape[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_sequence_for_move(fen: str, move: str):\n",
        "    board = chess.Board(fen)\n",
        "    legal_moves = engine.get_ordered_legal_moves(board)\n",
        "    try:\n",
        "        idx = legal_moves.index(move)\n",
        "    except ValueError:\n",
        "        return None\n",
        "    sequences = get_sequences_from_board(board)\n",
        "    if idx < len(sequences):\n",
        "        return sequences[idx]\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LIME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generadores de tableros vecinos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Generadores √∫nicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def alter_fen_remove_random_piece(fen: str) -> str | None:\n",
        "    \"\"\"\n",
        "    Elimina aleatoriamente una pieza (excepto los reyes) de una posici√≥n FEN de ajedrez.\n",
        "\n",
        "    La funci√≥n expande la parte del tablero en la notaci√≥n FEN, selecciona una fila con\n",
        "    al menos una pieza eliminable (cualquier pieza excepto 'K' o 'k'), y la reemplaza por\n",
        "    una casilla vac√≠a ('1'). Luego recompone la notaci√≥n FEN y verifica que el resultado\n",
        "    sea un FEN v√°lido.\n",
        "\n",
        "    Par√°metros:\n",
        "        fen (str): Una cadena en notaci√≥n FEN v√°lida.\n",
        "\n",
        "    Retorna:\n",
        "        str | None: Una nueva FEN con una pieza eliminada, si es v√°lida. \n",
        "                    Si no se pudo eliminar ninguna pieza o el FEN resultante no es v√°lido, devuelve None.\n",
        "    \"\"\"\n",
        "    board_part = fen.split(' ')[0]\n",
        "    rows = board_part.split('/')\n",
        "    rows_to_select = list(range(8))  # √çndices de fila (0=fila 8, 7=fila 1)\n",
        "\n",
        "    while rows_to_select:\n",
        "        row_index = np.random.choice(rows_to_select)\n",
        "        selected_row = rows[row_index]\n",
        "\n",
        "        # Expandir la fila FEN a una lista de 8 elementos\n",
        "        expanded = []\n",
        "        for c in selected_row:\n",
        "            if c.isdigit():\n",
        "                expanded.extend(['1'] * int(c))\n",
        "            else:\n",
        "                expanded.append(c)\n",
        "\n",
        "        # Buscar piezas que se puedan eliminar (excluye reyes y casillas vac√≠as)\n",
        "        candidates = [i for i, c in enumerate(expanded) if c not in {'1', 'K', 'k'}]\n",
        "        if not candidates:\n",
        "            rows_to_select.remove(row_index)\n",
        "            continue\n",
        "\n",
        "        # Eliminar una pieza aleatoria\n",
        "        selected_col = np.random.choice(candidates)\n",
        "        expanded[selected_col] = '1'\n",
        "\n",
        "        # Recompactar la fila a formato FEN\n",
        "        new_row = []\n",
        "        count = 0\n",
        "        for c in expanded:\n",
        "            if c == '1':\n",
        "                count += 1\n",
        "            else:\n",
        "                if count:\n",
        "                    new_row.append(str(count))\n",
        "                    count = 0\n",
        "                new_row.append(c)\n",
        "        if count:\n",
        "            new_row.append(str(count))\n",
        "        new_row_str = ''.join(new_row)\n",
        "\n",
        "        # Reconstruir el nuevo FEN\n",
        "        new_rows = rows.copy()\n",
        "        new_rows[row_index] = new_row_str\n",
        "        new_fen = '/'.join(new_rows) + ' ' + ' '.join(fen.split(' ')[1:])\n",
        "\n",
        "        # Validar FEN resultante\n",
        "        try:\n",
        "            board = chess.Board(new_fen)\n",
        "            if board.is_valid():\n",
        "                return new_fen\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Si el FEN es inv√°lido, probar otra fila\n",
        "        rows_to_select.remove(row_index)\n",
        "\n",
        "    return None  # No se pudo alterar v√°lidamente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encontrar_casilla_vacia_en_espiral_aleatoria(board, fila_inicial, col_inicial, max_radio=7) -> chess.Square | None:\n",
        "    \"\"\"\n",
        "    Busca una casilla vac√≠a aleatoria en el tablero dentro de un patr√≥n en espiral\n",
        "    desde una casilla central (fila_inicial, col_inicial), priorizando las m√°s cercanas.\n",
        "\n",
        "    En lugar de devolver siempre la primera vac√≠a encontrada, selecciona aleatoriamente\n",
        "    entre todas las vac√≠as dentro del primer radio con al menos una casilla libre.\n",
        "\n",
        "    Par√°metros:\n",
        "        board (chess.Board): El tablero de ajedrez actual.\n",
        "        fila_inicial (int): Fila de origen (0 arriba, 7 abajo).\n",
        "        col_inicial (int): Columna de origen (0 izquierda, 7 derecha).\n",
        "        max_radio (int): M√°xima distancia en casillas desde el centro a explorar.\n",
        "\n",
        "    Return:\n",
        "        chess.Square | None: Una casilla vac√≠a aleatoria cercana, o None si no se encuentra ninguna.\n",
        "    \"\"\"\n",
        "    for radio in range(1, max_radio + 1):\n",
        "        vacias = []\n",
        "        for dr in range(-radio, radio + 1):\n",
        "            for dc in range(-radio, radio + 1):\n",
        "                if max(abs(dr), abs(dc)) != radio:\n",
        "                    continue  # Solo borde del cuadrado\n",
        "                fila = fila_inicial + dr\n",
        "                col = col_inicial + dc\n",
        "                if 0 <= fila <= 7 and 0 <= col <= 7:\n",
        "                    square = chess.square(col, fila)\n",
        "                    if board.piece_at(square) is None:\n",
        "                        vacias.append(square)\n",
        "        if vacias:\n",
        "            return random.choice(vacias)\n",
        "    return None\n",
        "\n",
        "def alter_fen_move_piece_randomly(fen: str) -> str | None:\n",
        "    \"\"\"\n",
        "    Mueve una pieza cualquiera del tablero a la casilla vac√≠a m√°s cercana\n",
        "    (siguiendo una espiral desde su posici√≥n original).\n",
        "\n",
        "    Par√°metros:\n",
        "        fen (str): Notaci√≥n FEN del tablero original.\n",
        "\n",
        "    Return:\n",
        "        str | None: Un nuevo FEN con una pieza movida si fue posible y el tablero resultante es v√°lido,\n",
        "                    o None si no fue posible hacer un movimiento legalmente v√°lido.\n",
        "    \"\"\"\n",
        "    board = chess.Board(fen)\n",
        "    \n",
        "    # Buscar piezas presentes en el tablero\n",
        "    occupied_squares = [sq for sq in chess.SQUARES if board.piece_at(sq)]\n",
        "    if not occupied_squares:\n",
        "        return None\n",
        "\n",
        "    # Seleccionar una pieza aleatoriamente\n",
        "    selected_square = np.random.choice(occupied_squares)\n",
        "    piece = board.piece_at(selected_square)\n",
        "\n",
        "    # Buscar la casilla vac√≠a m√°s cercana desde esa pieza\n",
        "    row = chess.square_rank(selected_square)\n",
        "    col = chess.square_file(selected_square)\n",
        "    target_square = encontrar_casilla_vacia_en_espiral_aleatoria(board, row, col)\n",
        "\n",
        "    if target_square is None:\n",
        "        return None\n",
        "\n",
        "    # Mover la pieza\n",
        "    board.set_piece_at(target_square, piece)\n",
        "    board.remove_piece_at(selected_square)\n",
        "\n",
        "    # Verificar validez del tablero resultante\n",
        "    if board.is_valid():\n",
        "        return board.fen()\n",
        "    else:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def alter_fen_add_piece_randomly(fen: str) -> str | None:\n",
        "    \"\"\"\n",
        "    A√±ade una pieza menor (P, N, B / p, n, b) en una casilla vac√≠a aleatoria del tablero,\n",
        "    evitando colocar peones en las filas 1 y 8.\n",
        "    \n",
        "    Return:\n",
        "        - Nuevo FEN si se pudo realizar la alteraci√≥n.\n",
        "        - None si no fue posible alterar el tablero.\n",
        "    \"\"\"\n",
        "    piezas_permitidas = ['P', 'N', 'B', 'p', 'n', 'b']\n",
        "    max_por_tipo = {'P': 8, 'N': 2, 'B': 2, 'p': 8, 'n': 2, 'b': 2}\n",
        "    contador = {p: 0 for p in piezas_permitidas}\n",
        "\n",
        "    board = chess.Board(fen)\n",
        "\n",
        "    # Contar piezas existentes\n",
        "    for square in chess.SQUARES:\n",
        "        piece = board.piece_at(square)\n",
        "        if piece:\n",
        "            symbol = piece.symbol()\n",
        "            if symbol in contador:\n",
        "                contador[symbol] += 1\n",
        "\n",
        "    # Filtrar candidatas que a√∫n se pueden a√±adir\n",
        "    candidatas = [p for p in piezas_permitidas if contador[p] < max_por_tipo[p]]\n",
        "    if not candidatas:\n",
        "        return None\n",
        "\n",
        "    # Filtrar casillas vac√≠as legales (sin peones en filas 1 y 8)\n",
        "    casillas_vacias_legales = [\n",
        "        sq for sq in chess.SQUARES\n",
        "        if board.piece_at(sq) is None and chess.square_rank(sq) not in [0, 7]\n",
        "    ]\n",
        "    if not casillas_vacias_legales:\n",
        "        return None\n",
        "\n",
        "    # Intentar a√±adir una pieza\n",
        "    random.shuffle(candidatas)\n",
        "    random.shuffle(casillas_vacias_legales)\n",
        "    for pieza_symbol in candidatas:\n",
        "        pieza = chess.Piece.from_symbol(pieza_symbol)\n",
        "        for square in casillas_vacias_legales:\n",
        "            board.set_piece_at(square, pieza)\n",
        "            if board.is_valid():\n",
        "                return board.fen()\n",
        "            board.remove_piece_at(square)\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_altered_fen(fen: str) -> str:\n",
        "    alt_fen = None\n",
        "    retries = 0\n",
        "    while alt_fen is None and retries < 10:\n",
        "        r = np.random.rand()\n",
        "        if r < 0.2:\n",
        "            alt_fen = alter_fen_remove_random_piece(fen)\n",
        "        elif r < 0.5:\n",
        "            alt_fen = alter_fen_move_piece_randomly(fen)\n",
        "        else:\n",
        "            alt_fen = alter_fen_add_piece_randomly(fen)\n",
        "        retries += 1\n",
        "            \n",
        "    return alt_fen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generadores de conjuntos de tableros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_all_altered_fens(fen: str, allow_insert: bool = False) -> list[str]:\n",
        "    \"\"\"\n",
        "    Genera todos los FENs posibles aplicando tres tipos de alteraciones sin aleatoriedad:\n",
        "    1. Eliminaci√≥n de cualquier pieza (excepto rey)\n",
        "    2. Movimiento de cualquier pieza a una casilla vac√≠a\n",
        "    3. Inserci√≥n de nuevas piezas (opcional)\n",
        "\n",
        "    Solo se devuelven FENs v√°lidos seg√∫n las reglas de chess.Board.is_valid()\n",
        "\n",
        "    Parameters:\n",
        "    - fen: FEN original\n",
        "    - allow_insert: si True, se permiten inserciones de piezas nuevas\n",
        "\n",
        "    Returns:\n",
        "    - Lista de FENs alterados v√°lidos y √∫nicos\n",
        "    \"\"\"\n",
        "    board = chess.Board(fen)\n",
        "    altered_fens = set()\n",
        "\n",
        "    # 1. Eliminar una pieza\n",
        "    for square in chess.SQUARES:\n",
        "        piece = board.piece_at(square)\n",
        "        if piece and piece.symbol().lower() != 'k':\n",
        "            b = board.copy()\n",
        "            b.remove_piece_at(square)\n",
        "            if b.status() == chess.Status.BAD_CASTLING_RIGHTS:\n",
        "                b.castling_rights = b.clean_castling_rights()\n",
        "            \n",
        "            if b.is_valid():\n",
        "                altered_fens.add(b.fen())\n",
        "\n",
        "    # 2. Mover cada pieza a una casilla vac√≠a\n",
        "    occupied = [sq for sq in chess.SQUARES if board.piece_at(sq)]\n",
        "    empty = [sq for sq in chess.SQUARES if not board.piece_at(sq)]\n",
        "\n",
        "    for from_sq in occupied:\n",
        "        piece = board.piece_at(from_sq)\n",
        "        for to_sq in empty:\n",
        "            b = board.copy()\n",
        "            b.remove_piece_at(from_sq)\n",
        "            b.set_piece_at(to_sq, piece)\n",
        "            \n",
        "            if b.status() == chess.Status.BAD_CASTLING_RIGHTS:\n",
        "                b.castling_rights = b.clean_castling_rights()\n",
        "            if b.is_valid():\n",
        "                altered_fens.add(b.fen())\n",
        "\n",
        "    # 3. Insertar piezas nuevas en casillas vac√≠as (si se permite)\n",
        "    if allow_insert:\n",
        "        insertable_pieces = ['p', 'n', 'b', 'r', 'q', 'P', 'N', 'B', 'R', 'Q']\n",
        "        for sq in empty:\n",
        "            for p in insertable_pieces:\n",
        "                b = board.copy()\n",
        "                b.set_piece_at(sq, chess.Piece.from_symbol(p))\n",
        "                if b.status() == chess.Status.BAD_CASTLING_RIGHTS:\n",
        "                    b.castling_rights = b.clean_castling_rights()\n",
        "                if b.is_valid():\n",
        "                    altered_fens.add(b.fen())\n",
        "\n",
        "    return sorted(list(altered_fens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_all_valid_samples(fen: str, move: chess.Move):\n",
        "    samples = []\n",
        "    altered_fens = generate_all_altered_fens(fen, allow_insert=True)\n",
        "    for altered_fen in altered_fens:\n",
        "        board = chess.Board(altered_fen)\n",
        "        legal_moves = engine.get_ordered_legal_moves(board)\n",
        "        if move in legal_moves:\n",
        "            idx = legal_moves.index(move)\n",
        "            seqs = get_sequences_from_board(board)\n",
        "            if idx < len(seqs):\n",
        "                samples.append(seqs[idx])\n",
        "    return np.array(samples)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero de FENs alterados: 1040\n"
          ]
        }
      ],
      "source": [
        "altered_fens = generate_all_altered_fens(fen=\"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\", allow_insert=True)\n",
        "\n",
        "print(f'N√∫mero de FENs alterados: {len(altered_fens)}')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "engine.get_ordered_legal_moves(chess.Board(altered_fens[0])).index(chess.Move.from_uci('e2e4'))  # Verifica si el movimiento e2e4 es legal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero de FENs alterados v√°lidos: 1040\n"
          ]
        }
      ],
      "source": [
        "altered_fens = [f for f in altered_fens if chess.Board(f).is_valid()]\n",
        "print(f'N√∫mero de FENs alterados v√°lidos: {len(altered_fens)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N√∫mero de muestras v√°lidas generadas: 936\n"
          ]
        }
      ],
      "source": [
        "altered_samples = generate_all_valid_samples(fen=\"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\", move=chess.Move.from_uci(\"e2e4\"))\n",
        "print(f'N√∫mero de muestras v√°lidas generadas: {len(altered_samples)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(altered_samples, columns=token_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>&lt;turn&gt;</th>\n",
              "      <th>a8</th>\n",
              "      <th>b8</th>\n",
              "      <th>c8</th>\n",
              "      <th>d8</th>\n",
              "      <th>e8</th>\n",
              "      <th>f8</th>\n",
              "      <th>g8</th>\n",
              "      <th>h8</th>\n",
              "      <th>a7</th>\n",
              "      <th>...</th>\n",
              "      <th>&lt;en_passant_letter&gt;</th>\n",
              "      <th>&lt;en_passant_number&gt;</th>\n",
              "      <th>&lt;halfmove_1&gt;</th>\n",
              "      <th>&lt;halfmove_2&gt;</th>\n",
              "      <th>&lt;halfmove_3&gt;</th>\n",
              "      <th>&lt;fullmove_1&gt;</th>\n",
              "      <th>&lt;fullmove_2&gt;</th>\n",
              "      <th>&lt;fullmove_3&gt;</th>\n",
              "      <th>move</th>\n",
              "      <th>&lt;start&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows √ó 79 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [<turn>, a8, b8, c8, d8, e8, f8, g8, h8, a7, b7, c7, d7, e7, f7, g7, h7, a6, b6, c6, d6, e6, f6, g6, h6, a5, b5, c5, d5, e5, f5, g5, h5, a4, b4, c4, d4, e4, f4, g4, h4, a3, b3, c3, d3, e3, f3, g3, h3, a2, b2, c2, d2, e2, f2, g2, h2, a1, b1, c1, d1, e1, f1, g1, h1, <castling_1>, <castling_2>, <castling_3>, <castling_4>, <en_passant_letter>, <en_passant_number>, <halfmove_1>, <halfmove_2>, <halfmove_3>, <fullmove_1>, <fullmove_2>, <fullmove_3>, move, <start>]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 79 columns]"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['e4']!=30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Explicaci√≥n LIME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def LimeExplainer(fen: str, move: str):\n",
        "    \"\"\"\n",
        "    Explica un movimiento legal dado en una posici√≥n FEN utilizando LIME.\n",
        "    \n",
        "    Args:\n",
        "        fen (str): Notaci√≥n FEN de la posici√≥n.\n",
        "        move (str): Movimiento a explicar (en notaci√≥n UCI).\n",
        "        samples (int): N√∫mero de ejemplos perturbados a usar.\n",
        "\n",
        "    Return:\n",
        "        explanation: Objeto LimeExplanation o None si falla.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    tokenized_sequence = get_sequence_for_move(fen, move)\n",
        "    if tokenized_sequence is None:\n",
        "        print(f\"[ERROR] Movimiento {move} no es legal en el tablero dado.\")\n",
        "        return None\n",
        "\n",
        "    X_train = generate_all_valid_samples(fen, move)\n",
        "    if len(X_train) == 0:\n",
        "        print(f\"[WARNING] No se generaron muestras v√°lidas para el movimiento {move}.\")\n",
        "        return None\n",
        "    \n",
        "    X_train_no_duplicates = np.unique(X_train, axis=0)\n",
        "    print(f\"Total de muestras √∫nicas generadas: {len(X_train_no_duplicates)}\")\n",
        "    \n",
        "    explainer = LimeTabularExplainer(\n",
        "        training_data=X_train_no_duplicates,\n",
        "        feature_names=pos_labels,\n",
        "        categorical_features = list(range(len(pos_labels))), # Todas las caracter√≠sticas son categ√≥ricas\n",
        "        #categorical_names=cat_names,\n",
        "        mode='regression',\n",
        "        discretize_continuous=False,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    explanation = explainer.explain_instance(\n",
        "        data_row=tokenized_sequence,\n",
        "        predict_fn=predict_fn_xai,\n",
        "        num_features=100\n",
        "    )\n",
        "    return explanation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Gr√°ficas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tuplas_a_mapa_importancias(tuplas: list[tuple[str, float]]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convierte una lista de tuplas (como ('e4=30', 0.8)) en un mapa de calor 8x8 de importancias normalizadas.\n",
        "    \n",
        "    Args:\n",
        "        tuplas (list): Lista de tuplas (clave: 'e4=30', valor: float).\n",
        "    \n",
        "    Returns:\n",
        "        np.ndarray: Array 8x8 con valores normalizados en [-1, 1].\n",
        "    \"\"\"\n",
        "    mapa = np.zeros((8, 8), dtype=np.float32)\n",
        "    importancias = {}\n",
        "\n",
        "    for clave, valor in tuplas:\n",
        "        if '=' in clave:\n",
        "            nombre_casilla, _ = clave.split('=')\n",
        "            if nombre_casilla in chess.SQUARE_NAMES:\n",
        "                square = chess.parse_square(nombre_casilla)\n",
        "                fila = 7 - chess.square_rank(square)  # Fila visual (0 arriba, 7 abajo)\n",
        "                columna = chess.square_file(square)\n",
        "                importancias[(fila, columna)] = valor\n",
        "\n",
        "    if not importancias:\n",
        "        return mapa  # Vac√≠o\n",
        "\n",
        "    # Normalizaci√≥n\n",
        "    max_abs_val = max(abs(v) for v in importancias.values())\n",
        "    for (fila, col), val in importancias.items():\n",
        "        mapa[fila, col] = val / max_abs_val\n",
        "\n",
        "    return mapa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import chess\n",
        "import chess.svg\n",
        "from IPython.display import SVG, display\n",
        "\n",
        "def dibujar_tablero_con_mapa(\n",
        "    fen: str,\n",
        "    mapa_importancias: list[tuple[str, float]],\n",
        "    alpha_mult: float = 1,\n",
        "    save_path: str = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Dibuja un tablero de ajedrez resaltando las casillas con importancias.\n",
        "\n",
        "    Par√°metros:\n",
        "    - fen: cadena FEN que representa el tablero.\n",
        "    - mapa_importancias: lista de tuplas (str, float), donde str es una casilla con formato 'e4=30'\n",
        "      y float es la importancia asociada a esa casilla.\n",
        "    - alpha_mult: factor multiplicador del canal alfa.\n",
        "    - save_path: si se proporciona, se guarda la imagen SVG en esa ruta en lugar de mostrarla.\n",
        "    \"\"\"\n",
        "    board = chess.Board(fen)\n",
        "\n",
        "    # Mapea a: chess.SQUARE -> rgba color\n",
        "    def valor_a_color(valor):\n",
        "        alpha = min(abs(valor) * alpha_mult, 1.0)\n",
        "        if valor > 0:\n",
        "            return f'rgba(0, 255, 0, {alpha})'  # Verde\n",
        "        else:\n",
        "            return f'rgba(255, 0, 0, {alpha})'  # Rojo\n",
        "\n",
        "    # Crear diccionario de casillas y colores\n",
        "    colores = {}\n",
        "    for clave, valor in mapa_importancias:\n",
        "        if '=' not in clave:\n",
        "            continue\n",
        "        casilla_str = clave.split('=')[0]\n",
        "        if casilla_str in chess.SQUARE_NAMES:\n",
        "            square = chess.parse_square(casilla_str)\n",
        "            colores[square] = valor_a_color(valor)\n",
        "\n",
        "    # Generar SVG\n",
        "    svg = chess.svg.board(board=board, fill=colores)\n",
        "\n",
        "    # Guardar o mostrar\n",
        "    if save_path:\n",
        "        with open(save_path, 'w') as f:\n",
        "            f.write(svg)\n",
        "    else:\n",
        "        display(SVG(data=svg))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total de muestras √∫nicas generadas: 936\n",
            "sequences.shape[0]: 5000\n",
            "win_probs: (5000,)\n"
          ]
        }
      ],
      "source": [
        "# Creamos el tablero\n",
        "fen = 'rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1'\n",
        "explainer = LimeExplainer(fen, chess.Move.from_uci('e2e4'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('d8=22', -0.4508913606512875),\n",
              " ('d1=27', 0.4382037983936553),\n",
              " ('a1=26', 0.32929157935864123),\n",
              " ('c1=24', 0.31233282640147114),\n",
              " ('a8=20', -0.30430702943953425),\n",
              " ('h1=26', 0.29938620534316523),\n",
              " ('f1=24', 0.28955091438144276),\n",
              " ('h8=20', -0.27151064634468164),\n",
              " ('b1=25', 0.2679720545233792),\n",
              " ('c8=11', -0.24794055107649268),\n",
              " ('f8=11', -0.2432921064583447),\n",
              " ('g1=25', 0.23949110593378853),\n",
              " ('b8=19', -0.23288713739373826),\n",
              " ('g8=19', -0.21810618123013156),\n",
              " ('f7=18', -0.10040977410133677),\n",
              " ('a6=30', 0.10016641463500245),\n",
              " ('f2=23', 0.10005416570248764),\n",
              " ('g7=18', -0.09734659274412497),\n",
              " ('b2=23', 0.09381927012920833),\n",
              " ('d6=30', 0.08564709868319896),\n",
              " ('g6=30', 0.07749211638987336),\n",
              " ('g2=23', 0.07487919967574029),\n",
              " ('c2=23', 0.07428940786393277),\n",
              " ('c6=30', 0.0730203693770005),\n",
              " ('h6=30', 0.06358309667601635),\n",
              " ('c7=18', -0.06328276636334072),\n",
              " ('e7=18', -0.06049699244658064),\n",
              " ('d2=23', 0.05624417135700678),\n",
              " ('d7=18', -0.05551104513245101),\n",
              " ('f4=30', 0.05361545126186952),\n",
              " ('f6=30', 0.05288075477428522),\n",
              " ('b6=30', 0.04904215726774473),\n",
              " ('c3=30', 0.045041384122705794),\n",
              " ('h2=23', 0.04342060892693058),\n",
              " ('f5=30', 0.0391175502155522),\n",
              " ('h7=18', -0.03898343203976052),\n",
              " ('a2=23', 0.037835385516975004),\n",
              " ('e6=30', 0.037577893537449544),\n",
              " ('a5=30', 0.0356609741107721),\n",
              " ('h5=30', 0.03529726884283546),\n",
              " ('h4=30', 0.03494513001697234),\n",
              " ('g4=30', 0.03150473630627221),\n",
              " ('d5=30', 0.0299159656557491),\n",
              " ('c5=30', 0.029629342167855722),\n",
              " ('a7=18', -0.023429561883111263),\n",
              " ('a4=30', -0.02260407185973114),\n",
              " ('e1=28', -0.022207063737308227),\n",
              " ('<castling_3>=21', 0.01717294509721511),\n",
              " ('h3=30', 0.01638947237413695),\n",
              " ('a3=30', -0.016058907871127757),\n",
              " ('b4=30', 0.015753815342240702),\n",
              " ('e8=21', -0.013823282475483523),\n",
              " ('c4=30', 0.008048137768090373),\n",
              " ('<castling_2>=27', -0.007965542981523025),\n",
              " ('d3=30', -0.007599683920131369),\n",
              " ('d4=30', 0.006818264312390326),\n",
              " ('f3=30', 0.006728914452102513),\n",
              " ('e5=30', -0.00660957198654967),\n",
              " ('g3=30', 0.006235141592211685),\n",
              " ('<castling_4>=22', 0.005982891600444055),\n",
              " ('b7=18', -0.00581483600493207),\n",
              " ('<castling_1>=28', -0.003191211237680533),\n",
              " ('b3=30', 0.0030184141416802934),\n",
              " ('g5=30', 0.0005031988748667193),\n",
              " ('b5=30', -0.0002563366504315369),\n",
              " ('<fullmove_3>=30', 0.0),\n",
              " ('move=317', 0.0),\n",
              " ('<start>=0', 0.0),\n",
              " ('<halfmove_2>=30', 0.0),\n",
              " ('<halfmove_3>=30', 0.0),\n",
              " ('<fullmove_1>=1', 0.0),\n",
              " ('<fullmove_2>=30', 0.0),\n",
              " ('e3=30', 0.0),\n",
              " ('<en_passant_letter>=30', 0.0),\n",
              " ('<en_passant_number>=30', 0.0),\n",
              " ('<halfmove_1>=0', 0.0),\n",
              " ('<turn>=29', 0.0),\n",
              " ('e4=30', 0.0),\n",
              " ('e2=23', 0.0)]"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explainer.as_list()  # Para ver las caracter√≠sticas y sus importancias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/svg+xml": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\"><desc><pre>r n b q k b n r\n",
              "p p p p p p p p\n",
              ". . . . . . . .\n",
              ". . . . . . . .\n",
              ". . . . . . . .\n",
              ". . . . . . . .\n",
              "P P P P P P P P\n",
              "R N B Q K B N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\"/></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\"/></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\"/></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\"/><path d=\"M34 14l-3 3H14l-3-3\"/><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\"/><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\"/></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\"/><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\"/></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\"/><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\"/></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\"/></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\"/><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\"/><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\"/></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\"/><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\"/></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\"/><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\"/><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\"/></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\"/><circle cx=\"14\" cy=\"9\" r=\"2.75\"/><circle cx=\"22.5\" cy=\"8\" r=\"2.75\"/><circle cx=\"31\" cy=\"9\" r=\"2.75\"/><circle cx=\"39\" cy=\"12\" r=\"2.75\"/></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\"/><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\"/><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\"/></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\"/><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\"/><path d=\"M20 8h5\" stroke-linejoin=\"miter\"/><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\"/></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\"/><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\"/></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\"/></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\"/></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\"/></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\"/></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\"/></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\"/></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\"/></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\"/></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\"/></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\"/></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\"/></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\"/></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\"/></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\"/></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\"/></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.32929157935864123)\"/><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.2679720545233792)\"/><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.31233282640147114)\"/><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.4382037983936553)\"/><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.022207063737308227)\"/><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.28955091438144276)\"/><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.23949110593378853)\"/><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.29938620534316523)\"/><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.037835385516975004)\"/><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.09381927012920833)\"/><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.07428940786393277)\"/><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.05624417135700678)\"/><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.0)\"/><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.10005416570248764)\"/><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.07487919967574029)\"/><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.04342060892693058)\"/><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.016058907871127757)\"/><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.0030184141416802934)\"/><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.045041384122705794)\"/><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.007599683920131369)\"/><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.0)\"/><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.006728914452102513)\"/><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.006235141592211685)\"/><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.01638947237413695)\"/><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.02260407185973114)\"/><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.015753815342240702)\"/><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.008048137768090373)\"/><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.006818264312390326)\"/><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.0)\"/><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.05361545126186952)\"/><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.03150473630627221)\"/><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.03494513001697234)\"/><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.0356609741107721)\"/><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.0002563366504315369)\"/><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.029629342167855722)\"/><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.0299159656557491)\"/><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.00660957198654967)\"/><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.0391175502155522)\"/><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.0005031988748667193)\"/><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.03529726884283546)\"/><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.10016641463500245)\"/><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.04904215726774473)\"/><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.0730203693770005)\"/><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.08564709868319896)\"/><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.037577893537449544)\"/><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.05288075477428522)\"/><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.07749211638987336)\"/><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(0, 255, 0, 0.06358309667601635)\"/><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.023429561883111263)\"/><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.00581483600493207)\"/><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.06328276636334072)\"/><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.05551104513245101)\"/><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.06049699244658064)\"/><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.10040977410133677)\"/><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.09734659274412497)\"/><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.03898343203976052)\"/><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.30430702943953425)\"/><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.23288713739373826)\"/><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.24794055107649268)\"/><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.4508913606512875)\"/><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.013823282475483523)\"/><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.2432921064583447)\"/><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\"/><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.21810618123013156)\"/><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\"/><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" stroke=\"none\" fill=\"rgba(255, 0, 0, 0.27151064634468164)\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\"/><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\"/><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\"/><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\"/><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\"/><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\"/><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\"/><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\"/><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\"/><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\"/><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\"/><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\"/><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\"/></svg>"
            ],
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "feature_weights = explainer.as_list()\n",
        "dibujar_tablero_con_mapa(fen, feature_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fen = '1k6/8/8/8/8/8/7P/1K6 w - - 0 1'\n",
        "board = chess.Board(fen)\n",
        "tokenized_boards = get_sequences_from_board(board)\n",
        "moves = engine.get_ordered_legal_moves(board)\n",
        "\n",
        "background =  np.array([\n",
        "                        [29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
        " 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
        " 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  0,\n",
        " 30, 30,  1, 30, 30, 24,  0]] # Turno de blancas\n",
        "                       )\n",
        "\n",
        "explainer = shap.KernelExplainer(predict_fn_xai, background, algorithm=\"partition\")  # o kernel\n",
        "i=0\n",
        "shap_values = {}\n",
        "\n",
        "for tokenized_board, move in zip(tokenized_boards, moves):\n",
        "    print(tokenized_board.shape)\n",
        "    shap_values[move] = explainer(tokenized_board.reshape(1,-1))\n",
        "    i=i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for key, value in shap_values.items():\n",
        "    value.feature_names = pos_labels\n",
        "    print(f'Importancia SHAP para el movimiento {key}')\n",
        "    shap.plots.bar(value,max_display=10)\n",
        "    feature_weights = [(f\"{k}=\", v) for k, v in zip(value.feature_names, value.values[0])]\n",
        "    dibujar_tablero_con_mapa(fen, feature_weights, alpha_mult=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(shap_values.keys)\n",
        "print(moves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_shap_to_fen(fen :str, move:str):\n",
        "    \"\"\"\n",
        "    Apply SHAP to a FEN string.\n",
        "    fen: str\n",
        "    returns: shap_values: np.array of shape (n_samples, 1)\n",
        "    \"\"\"\n",
        "    board = chess.Board(fen)\n",
        "    legal_moves = engine.get_ordered_legal_moves(board)\n",
        "    move_index = np.where([move == x.uci() for x in legal_moves])[0][0]\n",
        "    print('move_index:', move_index)\n",
        "    tokenized_board = get_sequences_from_board(board)\n",
        "    turn = 29 if board.turn == chess.WHITE else 11\n",
        "    # Tablero vac√≠o para background\n",
        "    background = [turn, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
        " 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
        " 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  0,\n",
        " 30, 30,  1, 30, 30, 24,  0]\n",
        "\n",
        "    explainer = shap.Explainer(predict_fn_xai, background, algorithm=\"partition\")  # o kernel\n",
        "    shap_values = explainer(tokenized_board[move_index]) #.reshape(1, -1))\n",
        "    return shap_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "_, return_buckets_values = utils.get_uniform_buckets_edges_values(\n",
        "    num_return_buckets\n",
        ")\n",
        "\n",
        "def experimento_xai(fen, max_moves=5, plot_raw_att=False, plot_board_att_by_rows = True, \n",
        "                    plot_board_att_by_cols=True, plot_token_imp=True,\n",
        "                    plot_attention_rollout=True, plot_attention_flow=False,\n",
        "                    plot_shap=True, plot_lime=True,\n",
        "                    save_path=None\n",
        "                    ):\n",
        "    \n",
        "    # Creamos el tablero\n",
        "    board = chess.Board(fen)\n",
        "    # Obtenemos los pares tablero-jugada tokenizados\n",
        "    sequences = get_sequences_from_board(board)\n",
        "    # Predecimos los logits y mapas de atenci√≥n\n",
        "    results = predict_fn(sequences)\n",
        "    logits = np.array([log[:,-1,:] for log, att in results])\n",
        "    attention_maps = [att for log, att in results]\n",
        "    attention_maps = np.array(attention_maps).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "    \n",
        "    # Calculamos las probabilidades de victoria de cada jugada\n",
        "    sorted_legal_moves = engine.get_ordered_legal_moves(board)\n",
        "    win_probs = np.inner(np.exp(logits), return_buckets_values)\n",
        "    win_probs = win_probs.flatten()\n",
        "    \n",
        "    # Reorganizar el diccionario\n",
        "    reorganized_dict = {\n",
        "        move.uci(): {\n",
        "            \"logits\": logit.tolist() if isinstance(logit, np.ndarray) else logit,\n",
        "            \"win_probs\": win_prob.tolist() if isinstance(win_prob, np.ndarray) else win_prob\n",
        "        }\n",
        "        for move, logit, win_prob in zip(sorted_legal_moves, logits, win_probs)\n",
        "    }\n",
        "\n",
        "    # Guardar en archivo JSON\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    with open(f'{save_path}/results.json', 'w') as f:\n",
        "        json.dump(reorganized_dict, f, indent=2)\n",
        "    \n",
        "    if max_moves == None or max_moves > len(sorted_legal_moves):\n",
        "        max_moves = len(sorted_legal_moves)\n",
        "    \n",
        "    # Creamos los explicadores que nos hagan falta\n",
        "    if plot_shap:\n",
        "        turn = 29 if board.turn == chess.WHITE else 11\n",
        "        # Tablero vac√≠o para background\n",
        "        background = [turn, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
        "                        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,\n",
        "                        30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30,  0,\n",
        "                        30, 30,  1, 30, 30, 24,  0]\n",
        "        background = np.array(background).reshape(1, -1)\n",
        "        shap_explainer = shap.KernelExplainer(predict_fn_xai, background, algorithm=\"partition\")  # o kernel\n",
        "            \n",
        "   \n",
        "    # Ejecutamos los experimentos de xAI con las max_moves mejores jugadas\n",
        "    for i in np.argsort(win_probs)[:-max_moves-1:-1]:\n",
        "        print(f'  {sorted_legal_moves[i].uci()} -> {100*win_probs[i]:.1f}%')\n",
        "        # Mapa de atenci√≥n plano\n",
        "        if plot_raw_att:\n",
        "            os.makedirs(f'{save_path}/attention/79x79', exist_ok=True)\n",
        "            plot_attention_maps(attention_maps[i], token_labels=token_labels, \n",
        "                                save_path=f'{save_path}/attention/79x79/_{sorted_legal_moves[i].uci()}.png')\n",
        "            \n",
        "        # Mapa de atenci√≥n en el tablero\n",
        "        if plot_board_att_by_rows:\n",
        "            os.makedirs(f'{save_path}/attention/reordered_by_row', exist_ok=True)\n",
        "            plot_all_attention_heads(attention_maps[i], token_labels=token_labels, by_row=True,\n",
        "                                    save_path=f'{save_path}/attention/reordered_by_row/{sorted_legal_moves[i].uci()}.png')\n",
        "            \n",
        "        # Mapa de atenci√≥n en el tablero (traspuesto)\n",
        "        if plot_board_att_by_cols:\n",
        "            os.makedirs(f'{save_path}/attention/reordered_by_col', exist_ok=True)\n",
        "            plot_all_attention_heads(attention_maps[i], token_labels=token_labels, by_row=False,\n",
        "                                save_path=f'{save_path}/attention/reordered_by_col/{sorted_legal_moves[i].uci()}.png')\n",
        "        \n",
        "        # Attention rollout\n",
        "        if plot_attention_rollout:\n",
        "            os.makedirs(f'{save_path}/attention/attention_rollout', exist_ok=True)\n",
        "            attention_rollout_maps = attention_rollout(attention_maps[i], alpha=0.5)\n",
        "            plot_all_attention_heads(attention_rollout_maps.reshape(1,-1,79,79), token_labels=token_labels, scale_in_1=False,\n",
        "                                     save_path=f'{save_path}/attention/attention_rollout/{sorted_legal_moves[i].uci()}.png')\n",
        "        \n",
        "        # Attention flow\n",
        "        if plot_attention_flow:\n",
        "            os.makedirs(f'{save_path}/attention/attention_flow', exist_ok=True)\n",
        "            attention_flow_vals = np.zeros((79,))\n",
        "            for j in range(79):\n",
        "                attention_flow_vals[j] = compute_attention_flow(attention_maps[i], sink_token=j)\n",
        "            plot_attention_flow_heatmap(attention_flow_vals, token_labels=token_labels,\n",
        "                                        save_path=f'{save_path}/attention/attention_flow/{sorted_legal_moves[i].uci()}.png')\n",
        "            \n",
        "        # Importancia de los tokens\n",
        "        if plot_token_imp:\n",
        "            os.makedirs(f'{save_path}/token_importances/bars', exist_ok=True)\n",
        "            os.makedirs(f'{save_path}/token_importances/board', exist_ok=True)\n",
        "            grads, jacs = compute_token_grad_importance(\n",
        "                predictor,\n",
        "                params,   \n",
        "                sequences[i], \n",
        "                predictor_config\n",
        "            )\n",
        "            bar_plot_token_importances(grads, token_labels, save_path=f'{save_path}/token_importances/bars/{sorted_legal_moves[i].uci()}_grad.png')\n",
        "            bar_plot_token_importances(jacs, token_labels, save_path=f'{save_path}/token_importances/bars/{sorted_legal_moves[i].uci()}_jac.png')\n",
        "            board_plot_token_importances(grads, token_labels, save_path=f'{save_path}/token_importances/board/{sorted_legal_moves[i].uci()}_grad.png')\n",
        "            board_plot_token_importances(jacs, token_labels, save_path=f'{save_path}/token_importances/board/{sorted_legal_moves[i].uci()}_jac.png')\n",
        "        \n",
        "        # SHAP\n",
        "        if plot_shap:\n",
        "            os.makedirs(f'{save_path}/shap', exist_ok=True)\n",
        "\n",
        "            shap_values = shap_explainer(sequences[i].reshape(1,-1))\n",
        "            feature_weights = [(f\"{k}=0\", v) for k, v in zip(pos_labels, shap_values.values[0])]\n",
        "            dibujar_tablero_con_mapa(fen, feature_weights, alpha_mult=3,\n",
        "                                     save_path=f'{save_path}/shap/{sorted_legal_moves[i].uci()}.svg')\n",
        "            \n",
        "        if plot_lime:\n",
        "            os.makedirs(f'{save_path}/lime/', exist_ok=True)\n",
        "            print('lime')\n",
        "            print('fen', fen)\n",
        "            lime_explainer = LimeExplainer(fen, sorted_legal_moves[i])\n",
        "            feature_weights = lime_explainer.as_list()\n",
        "            dibujar_tablero_con_mapa(fen, feature_weights, alpha_mult=3,\n",
        "                                     save_path=f'{save_path}/lime/{sorted_legal_moves[i].uci()}.svg')\n",
        "            \n",
        "            \n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 1: Primera jugada de blancas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "board1 = chess.Board()\n",
        "fen1 = board1.fen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 20\n",
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "  e2e4 -> 53.5%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48c528e742cb44d08939581f8319eeb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n",
            "  d2d4 -> 53.1%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a63fe3578134f7d9d632fe4e9aa120e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n",
            "  g1f3 -> 52.6%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b9b1d3d1bba4a9bbafd53fa16164ddf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n",
            "  c2c4 -> 52.4%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0787325f60ff449a9ecc32e15294c81f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n",
            "  e2e3 -> 51.6%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdc665fa48694f3ab6c63b5e55ca3e02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n"
          ]
        }
      ],
      "source": [
        "experimento_xai(fen1,\n",
        "                max_moves=5,\n",
        "                plot_raw_att=False,\n",
        "                plot_board_att_by_rows = False, \n",
        "                plot_board_att_by_cols=False, \n",
        "                plot_token_imp=False,\n",
        "                plot_attention_rollout=False,\n",
        "                plot_attention_flow=False,\n",
        "                plot_shap=True,\n",
        "                plot_lime=False,\n",
        "                save_path='xai/experiment1_batched')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 2: Primera jugada de negras (1. e4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "board2 = chess.Board()\n",
        "board2.push(chess.Move.from_uci('e2e4'))\n",
        "fen2 = board2.fen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 20\n",
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "  c7c5 -> 47.0%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "511e77a399914eda8d46a8b9fcb69300",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n",
            "  e7e6 -> 46.3%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b900859d413a473580e03d38901dc47f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n",
            "  e7e5 -> 46.2%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "490f40a6d3e44175bbddd140cc6e3c7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n",
            "  d7d5 -> 45.6%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d90689347556413a96251a31c083dc9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n",
            "  c7c6 -> 44.7%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6330a32a49cd49aba71700a46abe3d45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2122\n",
            "win_probs: (2122,)\n"
          ]
        }
      ],
      "source": [
        "experimento_xai(fen2,\n",
        "                max_moves=5,\n",
        "                plot_raw_att=False,\n",
        "                plot_board_att_by_rows = False, \n",
        "                plot_board_att_by_cols=False, \n",
        "                plot_token_imp=False,\n",
        "                plot_attention_rollout=False,\n",
        "                plot_attention_flow=False,\n",
        "                plot_shap=True,\n",
        "                plot_lime=False,\n",
        "                save_path='xai/experiment2_batched')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 3 - Carrera de pe√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "board3 = chess.Board('1k6/8/8/8/8/8/7P/1K6 w - - 0 1')\n",
        "fen3 = board3.fen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 7\n",
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "  h2h4 -> 88.1%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14dbcd702e964e6fa430df7adc67ee9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 14\n",
            "win_probs: (14,)\n",
            "  h2h3 -> 50.4%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a67f7aa74bfe4c838557f0dcf86b1c44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 14\n",
            "win_probs: (14,)\n",
            "  b1c2 -> 50.1%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2ac39496ebf415fba20d692aa2dc726",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 14\n",
            "win_probs: (14,)\n",
            "  b1a1 -> 50.1%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de9900c3df0747d7a7a44027277d088c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 14\n",
            "win_probs: (14,)\n",
            "  b1b2 -> 50.1%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d459a89fa39402ba180edf7fb0ecf02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 14\n",
            "win_probs: (14,)\n"
          ]
        }
      ],
      "source": [
        "experimento_xai(fen3, \n",
        "                max_moves=5,\n",
        "                plot_raw_att=False,\n",
        "                plot_board_att_by_rows = False, \n",
        "                plot_board_att_by_cols=False, \n",
        "                plot_token_imp=False,\n",
        "                plot_attention_rollout=False,\n",
        "                plot_attention_flow=False,\n",
        "                plot_shap=True,\n",
        "                plot_lime=False,\n",
        "                save_path='xai/experiment3_batched')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 3.2 - Carrera de pe√≥n (negras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "board3_b = chess.Board('1k6/8/8/8/8/8/7P/1K6 b - - 0 1')\n",
        "fen3_b = board3_b.fen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 5\n",
            "  b8c7 -> 49.7%\n",
            "lime\n",
            "fen 1k6/8/8/8/8/8/7P/1K6 b - - 0 1\n",
            "Total de muestras √∫nicas generadas: 579\n",
            "sequences.shape[0]: 5000\n",
            "win_probs: (5000,)\n",
            "  b8c8 -> 49.7%\n",
            "lime\n",
            "fen 1k6/8/8/8/8/8/7P/1K6 b - - 0 1\n",
            "Total de muestras √∫nicas generadas: 587\n",
            "sequences.shape[0]: 5000\n",
            "win_probs: (5000,)\n",
            "  b8b7 -> 12.3%\n",
            "lime\n",
            "fen 1k6/8/8/8/8/8/7P/1K6 b - - 0 1\n",
            "Total de muestras √∫nicas generadas: 585\n",
            "sequences.shape[0]: 5000\n",
            "win_probs: (5000,)\n",
            "  b8a8 -> 11.2%\n",
            "lime\n",
            "fen 1k6/8/8/8/8/8/7P/1K6 b - - 0 1\n",
            "Total de muestras √∫nicas generadas: 593\n",
            "sequences.shape[0]: 5000\n",
            "win_probs: (5000,)\n",
            "  b8a7 -> 11.0%\n",
            "lime\n",
            "fen 1k6/8/8/8/8/8/7P/1K6 b - - 0 1\n",
            "Total de muestras √∫nicas generadas: 589\n",
            "sequences.shape[0]: 5000\n",
            "win_probs: (5000,)\n"
          ]
        }
      ],
      "source": [
        "experimento_xai(fen3_b, \n",
        "                max_moves=5,\n",
        "                plot_raw_att=False,\n",
        "                plot_board_att_by_rows = False, \n",
        "                plot_board_att_by_cols=False, \n",
        "                plot_token_imp=False,\n",
        "                plot_attention_rollout=False,\n",
        "                plot_attention_flow=False,\n",
        "                plot_shap=False,\n",
        "                plot_lime=True,\n",
        "                save_path='xai/experiment3_batched/black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 4 - Mates del pasillo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "board4 = chess.Board('1k6/ppp4r/8/8/8/8/PPP3R1/1K6 w - - 0 1')\n",
        "fen4 = board4.fen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 19\n",
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "  g2g8 -> 99.6%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff59feb9bc2c434c8f4df581a7f60eaf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2046\n",
            "win_probs: (2046,)\n",
            "  a2a4 -> 50.3%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaab42dda3f2416b967fbc3ed28c91b3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2046\n",
            "win_probs: (2046,)\n",
            "  b2b3 -> 50.2%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db2aee736b484fcbbc855e49c213ec39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2046\n",
            "win_probs: (2046,)\n",
            "  a2a3 -> 50.2%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c1229b54bbe402cb9ccf3149526ff93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2046\n",
            "win_probs: (2046,)\n",
            "  g2g1 -> 50.2%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e021dda02f1405186e5bbcf311fa742",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 2046\n",
            "win_probs: (2046,)\n"
          ]
        }
      ],
      "source": [
        "experimento_xai(fen4, \n",
        "                max_moves=5,\n",
        "                plot_raw_att=False,\n",
        "                plot_board_att_by_rows = False, \n",
        "                plot_board_att_by_cols=False, \n",
        "                plot_token_imp=False,\n",
        "                plot_attention_rollout=False,\n",
        "                plot_attention_flow=False,\n",
        "                plot_shap=True,\n",
        "                plot_lime=False,\n",
        "                save_path='xai/experiment4_batched')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 4.2 - Mates del pasillo (negras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board4_b = chess.Board('1k6/ppp4r/8/8/8/8/PPP3R1/1K6 b - - 0 1')\n",
        "fen4 =  board4_b.fen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experimento_xai(fen4, \n",
        "                max_moves=5,\n",
        "                plot_raw_att=False,\n",
        "                plot_board_att_by_rows = False, \n",
        "                plot_board_att_by_cols=False, \n",
        "                plot_token_imp=False,\n",
        "                plot_attention_rollout=False,\n",
        "                plot_attention_flow=False,\n",
        "                plot_shap=True,\n",
        "                plot_lime=False,\n",
        "                save_path='xai/experiment4_batched/black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 5 - CrossMate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "board5 = chess.Board('k7/6b1/5q2/8/8/4Q3/5B2/1K6 w - - 0 1')\n",
        "fen5 = board5.fen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 30\n",
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "  e3a7 -> 99.6%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1726b516f5a405b82a8bae72a20efb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 126\n",
            "win_probs: (126,)\n",
            "  e3e8 -> 53.0%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aee4a01e69be4687b954615ad60e74c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 126\n",
            "win_probs: (126,)\n",
            "  e3e4 -> 51.6%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eadca32ccf3541f68fade10be2a891e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 126\n",
            "win_probs: (126,)\n",
            "  e3a3 -> 51.1%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86f24e32aec240e4a2ea224d3582c1de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 126\n",
            "win_probs: (126,)\n",
            "  b1c2 -> 50.2%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f74c4ba77c944a8b873a5c44d7f23c6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sequences.shape[0]: 1\n",
            "win_probs: (1,)\n",
            "sequences.shape[0]: 126\n",
            "win_probs: (126,)\n"
          ]
        }
      ],
      "source": [
        "experimento_xai(fen5, \n",
        "                max_moves=5,\n",
        "                plot_raw_att=False,\n",
        "                plot_board_att_by_rows = False, \n",
        "                plot_board_att_by_cols=False, \n",
        "                plot_token_imp=False,\n",
        "                plot_attention_rollout=False,\n",
        "                plot_attention_flow=False,\n",
        "                plot_shap=True,\n",
        "                plot_lime=False,\n",
        "                save_path='xai/experiment5_batched')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimento 5.2 - CrossMate (negras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board5_b = chess.Board('k7/6b1/5q2/8/8/4Q3/5B2/1K6 b - - 0 1')\n",
        "fen5_b = board5_b.fen()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experimento_xai(fen5_b, \n",
        "                max_moves=1,\n",
        "                plot_raw_att=False,\n",
        "                plot_board_att_by_rows=True, \n",
        "                plot_board_att_by_cols=True, \n",
        "                plot_token_imp=False,\n",
        "                plot_attention_rollout=False,\n",
        "                plot_attention_flow=False,\n",
        "                plot_shap=False,\n",
        "                plot_lime=True,\n",
        "                save_path='xai/experiment5_batched/black')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diferencia de atenciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experimento 1: Alteraciones en Carrera de pe√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board3 = chess.Board('1k6/8/8/8/8/8/7P/1K6 w - - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_3 = get_sequences_from_board(board3)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_3 = predict_fn(sequences_3)\n",
        "logits_3 = np.array([log[:,-1,:] for log, att in results_3])\n",
        "attention_maps_3 = [att for log, att in results_3]\n",
        "attention_maps_3 = np.array(attention_maps_3).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_3 = engine.get_ordered_legal_moves(board3)\n",
        "win_probs_3 = np.inner(np.exp(logits_3), return_buckets_values)\n",
        "win_probs_3 = win_probs_3.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_3 = np.argsort(win_probs_3)[::-1]\n",
        "for i in ordered_indices_3:\n",
        "    print(f'  {sorted_legal_moves_3[i].uci()} -> {100*win_probs_3[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Diferencia entre jugar h4 (buena) y h3 (mala)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_maps_3_h4 = attention_maps_3[ordered_indices_3[0]]\n",
        "attention_maps_3_h3 = attention_maps_3[ordered_indices_3[1]]\n",
        "diff_attention_map_3_h4_h3 = attention_maps_3_h4 - attention_maps_3_h3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_3_h4_h3, token_labels, by_row=True, ,\n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/h4vsh3_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_3_h4_h3, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/h4vsh3_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Diferencia entre jugar h4 (buena) y Kc2 (mala)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_maps_3_h4 = attention_maps_3[ordered_indices_3[0]]\n",
        "attention_maps_3_Kc2 = attention_maps_3[ordered_indices_3[2]]\n",
        "diff_attention_map_3_h4_Kc2 = attention_maps_3_h4 - attention_maps_3_Kc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_3_h4_Kc2, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/h4vsKc3_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_3_h4_Kc2, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/h4vsKc3_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Diferencia entre jugar h3 (mala) y Kc2 (mala)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_maps_3_h3 = attention_maps_3[ordered_indices_3[1]]\n",
        "attention_maps_3_Kc2 = attention_maps_3[ordered_indices_3[2]]\n",
        "diff_attention_map_3_h3_Kc2 = attention_maps_3_h3 - attention_maps_3_Kc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_3_h3_Kc2, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/h3vsKc2_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_3_h3_Kc2, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/h3vsKc2_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tablero Alternativo 1: Mover el peon de h2 a g2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board3_alt1 = chess.Board('1k6/8/8/8/8/8/6P1/1K6 w - - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_3_alt1 = get_sequences_from_board(board3_alt1)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_3_alt1 = predict_fn(sequences_3_alt1)\n",
        "logits_3_alt1 = np.array([log[:,-1,:] for log, att in results_3_alt1])\n",
        "attention_maps_3_alt1 = [att for log, att in results_3_alt1]\n",
        "attention_maps_3_alt1 = np.array(attention_maps_3_alt1).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_3_alt1 = engine.get_ordered_legal_moves(board3_alt1)\n",
        "win_probs_3_alt1 = np.inner(np.exp(logits_3_alt1), return_buckets_values)\n",
        "win_probs_3_alt1 = win_probs_3_alt1.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_3_alt1 = np.argsort(win_probs_3_alt1)[::-1]\n",
        "for i in ordered_indices_3_alt1:\n",
        "    print(f'  {sorted_legal_moves_3_alt1[i].uci()} -> {100*win_probs_3_alt1[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Comparativa Kc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_maps_3_Kc2_alt1 = attention_maps_3_alt1[ordered_indices_3_alt1[0]]\n",
        "attention_maps_3_Kc2 = attention_maps_3[ordered_indices_3[2]]\n",
        "diff_attention_map_3_Kc2_Kc2alt1 = attention_maps_3_Kc2 - attention_maps_3_Kc2_alt1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_3_Kc2_Kc2alt1, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/Kc2vsKc2alt1_row.png')\n",
        "plot_all_attention_heads(diff_attention_map_3_Kc2_Kc2alt1, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/Kc2vsKc2alt1_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Comparativa avance peones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_maps_3_h4 = attention_maps_3[ordered_indices_3[0]]\n",
        "attention_maps_3_g4_alt1 = attention_maps_3_alt1[ordered_indices_3_alt1[-1]]\n",
        "diff_attention_map_3_h4_g4alt1 = attention_maps_3_h4 - attention_maps_3_g4_alt1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_3_h4_g4alt1, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/h4vsg4alt1_row.png')\n",
        "plot_all_attention_heads(diff_attention_map_3_h4_g4alt1, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment3_batched/attention_comparatives/h4vsg4alt1_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Secuencia de avance del pe√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "secuencia_movimientos = ['h2h4', 'b8c7', 'h4h5', 'c7d7', 'h5h6', 'd7e7', 'h6h7', 'e7f7', 'h7h8q']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board3_avance = board3.copy()\n",
        "logits_3_avance = []\n",
        "attention_maps_3_avance = []\n",
        "\n",
        "for move in secuencia_movimientos:\n",
        "    \n",
        "    sequences_3_avance = get_sequences_from_board(board3_avance)\n",
        "    results_3_avance_i = predict_fn(sequences_3_avance)\n",
        "    logits_3_avance_i = np.array([log[:,-1,:] for log, att in results_3_avance_i])\n",
        "    attention_maps_3_avance_i = [att for log, att in results_3_avance_i]\n",
        "    attention_maps_3_avance_i = np.array(attention_maps_3_avance_i).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "    \n",
        "    logits_3_avance.append(logits_3_avance_i)\n",
        "    attention_maps_3_avance.append(attention_maps_3_avance_i[engine.get_ordered_legal_moves(board3_avance)\n",
        "                                                                 .index(chess.Move.from_uci(move))])\n",
        "    \n",
        "    board3_avance.push(chess.Move.from_uci(move))\n",
        "    print(board3_avance.fen())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for move, logits, attention_maps in zip(secuencia_movimientos, logits_3_avance, attention_maps_3_avance):\n",
        "    print(f'Movimiento: {move}')\n",
        "    print('Logits shape:', logits.shape)\n",
        "    print('Attention maps shape:', attention_maps.shape)\n",
        "    \n",
        "    plot_all_attention_heads(attention_maps, token_labels, by_row=True, \n",
        "                             save_path=f'xai/experiment3_batched/secuencia_avance/attention/reordered_by_row/{move}.png')\n",
        "    \n",
        "    plot_all_attention_heads(attention_maps, token_labels, by_row=False, \n",
        "                             save_path=f'xai/experiment3_batched/secuencia_avance/attention/reordered_by_col/{move}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experimento 2: Alteraciones en Mates del Pasillo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board4 = chess.Board('1k6/ppp4r/8/8/8/8/PPP3R1/1K6 w - - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_4 = get_sequences_from_board(board4)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_4 = predict_fn(sequences_4)\n",
        "logits_4 = np.array([log[:,-1,:] for log, att in results_4])\n",
        "attention_maps_4 = [att for log, att in results_4]\n",
        "attention_maps_4 = np.array(attention_maps_4).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_4 = engine.get_ordered_legal_moves(board4)\n",
        "win_probs_4 = np.inner(np.exp(logits_4), return_buckets_values)\n",
        "win_probs_4 = win_probs_4.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_4 = np.argsort(win_probs_4)[::-1]\n",
        "for i in ordered_indices_4:\n",
        "    print(f'  {sorted_legal_moves_4[i].uci()} -> {100*win_probs_4[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Diferencia entre mejor jugada (Rg8#) y segunda mejor (a4 - empate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_maps_4_Rg8 = attention_maps_4[ordered_indices_4[0]]\n",
        "attention_maps_4_a4 = attention_maps_4[ordered_indices_4[1]]\n",
        "diff_attention_map_4_Rg8_a4 = attention_maps_4_Rg8 - attention_maps_4_a4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('xai/experiment4_batched/attention_comparatives', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_4_Rg8_a4, token_labels, by_row=True, \n",
        "                         save_path='xai/experiment4_batched/attention_comparatives/Rg8_a4_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_4_Rg8_a4, token_labels, by_row=False, \n",
        "                         save_path='xai/experiment4_batched/attention_comparatives/Rg8_a4_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Diferencia entre turno de blancas y negras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board4_b = chess.Board('1k6/ppp4r/8/8/8/8/PPP3R1/1K6 b - - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_4_b = get_sequences_from_board(board4_b)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_4_b = predict_fn(sequences_4_b)\n",
        "logits_4_b = np.array([log[:,-1,:] for log, att in results_4_b])\n",
        "attention_maps_4_b = [att for log, att in results_4_b]\n",
        "attention_maps_4_b = np.array(attention_maps_4_b).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_4_b = engine.get_ordered_legal_moves(board4_b)\n",
        "win_probs_4_b = np.inner(np.exp(logits_4_b), return_buckets_values)\n",
        "win_probs_4_b = win_probs_4_b.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_4_b = np.argsort(win_probs_4_b)[::-1]\n",
        "for i in ordered_indices_4_b:\n",
        "    print(f'  {sorted_legal_moves_4_b[i].uci()} -> {100*win_probs_4_b[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_maps_4_Rg8 = attention_maps_4[ordered_indices_4[0]]\n",
        "attention_maps_4_b_Rh1 = attention_maps_4_b[ordered_indices_4_b[0]]\n",
        "diff_attention_map_4_Rg8_b_Rh1 = attention_maps_4_Rg8 - attention_maps_4_b_Rh1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('xai/experiment4_batched/attention_comparatives', exist_ok=True)\n",
        "os.makedirs('xai/experiment4_batched/black', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_4_Rg8_b_Rh1, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment4_batched/attention_comparatives/turnwhite_vs_turnblack_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_4_Rg8_b_Rh1, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment4_batched/attention_comparatives/turnwhite_vs_turnblack_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cambio de la torre negra por un alfil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board4_alt = chess.Board('1k6/ppp4b/8/8/8/8/PPP3R1/1K6 w - - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_4_alt = get_sequences_from_board(board4_alt)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_4_alt = predict_fn(sequences_4_alt)\n",
        "logits_4_alt = np.array([log[:,-1,:] for log, att in results_4_alt])\n",
        "attention_maps_4_alt = [att for log, att in results_4_alt]\n",
        "attention_maps_4_alt = np.array(attention_maps_4_alt).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_4_alt = engine.get_ordered_legal_moves(board4_alt)\n",
        "win_probs_4_alt = np.inner(np.exp(logits_4_alt), return_buckets_values)\n",
        "win_probs_4_alt = win_probs_4_alt.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_4_alt = np.argsort(win_probs_4_alt)[::-1]\n",
        "for i in ordered_indices_4_alt:\n",
        "    print(f'  {sorted_legal_moves_4_alt[i].uci()} -> {100*win_probs_4_alt[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board4_alt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_legal_moves_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_4_alt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx_Rg8 = sorted_legal_moves_4.index(chess.Move.from_uci('g2g8'))\n",
        "idx_Rg8_alt1 = sorted_legal_moves_4_alt.index(chess.Move.from_uci('g2g8'))\n",
        "\n",
        "attention_maps_4_Rg8 = attention_maps_4[idx_Rg8]\n",
        "attention_maps_4_alt_Rg8 = attention_maps_4_alt[idx_Rg8_alt1]\n",
        "diff_attention_map_Rg8_alt_Rg8 = attention_maps_4_Rg8 - attention_maps_4_alt_Rg8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('xai/experiment4_batched/attention_comparatives', exist_ok=True)\n",
        "os.makedirs('xai/experiment4_batched/bishop', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(attention_maps_4_alt_Rg8, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment4_batched/bishop/g2g8_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(attention_maps_4_alt_Rg8, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment4_batched/bishop/g2g8_col.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_Rg8_alt_Rg8, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment4_batched/attention_comparatives/g2g8R_vs_g2g8b_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_Rg8_alt_Rg8, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment4_batched/attention_comparatives/g2g8R_vs_g2g8b_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experimento 3: Alteraciones en CrossMate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board5 = chess.Board('k7/6b1/5q2/8/8/4Q3/5B2/1K6 w - - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_5 = get_sequences_from_board(board5)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_5 = predict_fn(sequences_5)\n",
        "logits_5 = np.array([log[:,-1,:] for log, att in results_5])\n",
        "attention_maps_5 = [att for log, att in results_5]\n",
        "attention_maps_5 = np.array(attention_maps_5).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_5 = engine.get_ordered_legal_moves(board5)\n",
        "win_probs_5 = np.inner(np.exp(logits_5), return_buckets_values)\n",
        "win_probs_5 = win_probs_5.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_5 = np.argsort(win_probs_5)[::-1]\n",
        "for i in ordered_indices_5:\n",
        "    print(f'  {sorted_legal_moves_5[i].uci()} -> {100*win_probs_5[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Alteraci√≥n 1: Cambio de turno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board5_b = chess.Board('k7/6b1/5q2/8/8/4Q3/5B2/1K6 b - - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_5_b = get_sequences_from_board(board5_b)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_5_b = predict_fn(sequences_5_b)\n",
        "logits_5_b = np.array([log[:,-1,:] for log, att in results_5_b])\n",
        "attention_maps_5_b = [att for log, att in results_5_b]\n",
        "attention_maps_5_b = np.array(attention_maps_5_b).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_5_b = engine.get_ordered_legal_moves(board5_b)\n",
        "win_probs_5_b = np.inner(np.exp(logits_5_b), return_buckets_values)\n",
        "win_probs_5_b = win_probs_5_b.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_5_b = np.argsort(win_probs_5_b)[::-1]\n",
        "for i in ordered_indices_5_b:\n",
        "    print(f'  {sorted_legal_moves_5_b[i].uci()} -> {100*win_probs_5_b[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "attention_maps_5_Qa7 = attention_maps_5[ordered_indices_5[0]]\n",
        "attention_maps_5_b_Qb2 = attention_maps_5_b[ordered_indices_5_b[0]]\n",
        "diff_attention_map_5_Qa7_b_Qb2 = attention_maps_5_Qa7 - attention_maps_5_b_Qb2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('xai/experiment5_batched/attention_comparatives', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_5_Qa7_b_Qb2, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment5_batched/attention_comparatives/whiteturn_vs_blackturn_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_5_Qa7_b_Qb2, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment5_batched/attention_comparatives/whiteturn_vs_blackturn_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Alteraci√≥n 2: Borrado de alfil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board5_alt1 = chess.Board('k7/6b1/5q2/8/8/4Q3/8/1K6 w - - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_5_alt1 = get_sequences_from_board(board5_alt1)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_5_alt1 = predict_fn(sequences_5_alt1)\n",
        "logits_5_alt1 = np.array([log[:,-1,:] for log, att in results_5_alt1])\n",
        "attention_maps_5_alt1 = [att for log, att in results_5_alt1]\n",
        "attention_maps_5_alt1 = np.array(attention_maps_5_alt1).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_5_alt1 = engine.get_ordered_legal_moves(board5_alt1)\n",
        "win_probs_5_alt1 = np.inner(np.exp(logits_5_alt1), return_buckets_values)\n",
        "win_probs_5_alt1 = win_probs_5_alt1.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_5_alt1 = np.argsort(win_probs_5_alt1)[::-1]\n",
        "for i in ordered_indices_5_alt1:\n",
        "    print(f'  {sorted_legal_moves_5_alt1[i].uci()} -> {100*win_probs_5_alt1[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board5_alt1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Buscamos la jugada Qa7 en el tablero original y en el alternativo\n",
        "idx_Qa7 = sorted_legal_moves_5.index(chess.Move.from_uci('e3a7'))\n",
        "idx_Qa7_alt1 = sorted_legal_moves_5_alt1.index(chess.Move.from_uci('e3a7'))\n",
        "\n",
        "attention_maps_5_Qa7 = attention_maps_5[idx_Qa7]\n",
        "attention_maps_5_alt1_Qa7 = attention_maps_5_alt1[idx_Qa7_alt1]\n",
        "diff_attention_map_5_Qa7_alt1_Qa7 = attention_maps_5_Qa7 - attention_maps_5_alt1_Qa7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('xai/experiment5_batched/attention_comparatives', exist_ok=True)\n",
        "os.makedirs('xai/experiment5_batched/nobishop', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(attention_maps_5_alt1_Qa7, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment5_batched/nobishop/Qa7nobishop_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(attention_maps_5_alt1_Qa7, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment5_batched/nobishop/Qa7nobishop_col.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_5_Qa7_alt1_Qa7, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment5_batched/attention_comparatives/Qa7_vs_Qa7nobishop_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_5_Qa7_alt1_Qa7, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment5_batched/attention_comparatives/Qa7_vs_Qa7nobishop_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Alteraci√≥n 3: Cambio de alfil por caballo coordinante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board5_alt2 = chess.Board('k7/6b1/2N2q2/8/8/4Q3/8/1K6 w - - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_5_alt2 = get_sequences_from_board(board5_alt2)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_5_alt2 = predict_fn(sequences_5_alt2)\n",
        "logits_5_alt2 = np.array([log[:,-1,:] for log, att in results_5_alt2])\n",
        "attention_maps_5_alt2 = [att for log, att in results_5_alt2]\n",
        "attention_maps_5_alt2 = np.array(attention_maps_5_alt2).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_5_alt2 = engine.get_ordered_legal_moves(board5_alt2)\n",
        "win_probs_5_alt2 = np.inner(np.exp(logits_5_alt2), return_buckets_values)\n",
        "win_probs_5_alt2 = win_probs_5_alt2.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_5_alt2 = np.argsort(win_probs_5_alt2)[::-1]\n",
        "for i in ordered_indices_5_alt2:\n",
        "    print(f'  {sorted_legal_moves_5_alt2[i].uci()} -> {100*win_probs_5_alt2[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board5_alt2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Buscamos la jugada Qa7 en el tablero original y en el alternativo\n",
        "idx_Qa7 = sorted_legal_moves_5.index(chess.Move.from_uci('e3a7'))\n",
        "idx_Qa7_alt2 = sorted_legal_moves_5_alt2.index(chess.Move.from_uci('e3a7'))\n",
        "\n",
        "attention_maps_5_Qa7 = attention_maps_5[idx_Qa7]\n",
        "attention_maps_5_alt2_Qa7 = attention_maps_5_alt2[idx_Qa7_alt2]\n",
        "diff_attention_map_5_Qa7_alt2_Qa7 = attention_maps_5_Qa7 - attention_maps_5_alt2_Qa7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('xai/experiment5_batched/attention_comparatives', exist_ok=True)\n",
        "os.makedirs('xai/experiment5_batched/knight', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(attention_maps_5_alt2_Qa7, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment5_batched/knight/Qa7knight_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(attention_maps_5_alt2_Qa7, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment5_batched/knight/Qa7knight_col.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_5_Qa7_alt2_Qa7, token_labels, by_row=True,  \n",
        "                         save_path='xai/experiment5_batched/attention_comparatives/Qa7_vs_Qa7knight_row.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attention_heads(diff_attention_map_5_Qa7_alt2_Qa7, token_labels, by_row=False,  \n",
        "                         save_path='xai/experiment5_batched/attention_comparatives/Qa7_vs_Qa7knight_col.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "board3 = chess.Board('rnbqkbnr/pppppppp/8/8/8/R7/PPPPPPPP/1NBQKBNR w KQkq - 0 1')\n",
        "# Obtenemos los pares tablero-jugada tokenizados\n",
        "sequences_3 = get_sequences_from_board(board3)\n",
        "# Predecimos los logits y mapas de atenci√≥n\n",
        "results_3 = predict_fn(sequences_3)\n",
        "logits_3 = np.array([log[:,-1,:] for log, att in results_3])\n",
        "attention_maps_3 = [att for log, att in results_3]\n",
        "attention_maps_3 = np.array(attention_maps_3).reshape(-1, num_layers, num_heads, 79, 79)\n",
        "# Calculamos las probabilidades de victoria de cada jugada\n",
        "sorted_legal_moves_3 = engine.get_ordered_legal_moves(board3)\n",
        "win_probs_3 = np.inner(np.exp(logits_3), return_buckets_values)\n",
        "win_probs_3 = win_probs_3.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ordered_indices_3 = np.argsort(win_probs_3)[::-1]\n",
        "for i in ordered_indices_3:\n",
        "    print(f'  {sorted_legal_moves_3[i].uci()} -> {100*win_probs_3[i]:.1f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//third_party/deepmind/searchless_chess/src:searchless_chess",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
